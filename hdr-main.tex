%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% LaTeX book template                           %%
%% Author:  Amber Jain (http://amberj.devio.us/) %%
%% License: ISC license                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[12pt,french,twoside,openright]{book}

%\documentclass[a4paper,11pt]{book}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Source: http://en.wikibooks.org/wiki/LaTeX/Hyperlinks %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[francais]{babel}
\usepackage{pdfpages}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{a4}
\usepackage{indentfirst}
\usepackage{fancyhdr}
\usepackage{varioref}
\usepackage{makeidx}

%\usepackage{apacite}
%\usepackage[longnamesfirst,nonamebreak]{natbib}

\usepackage[usenames,dvipsnames]{color}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{fancy}

\addtolength{\headwidth}{\marginparsep}
\addtolength{\headwidth}{\marginparwidth}
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\fancyhf{}
\fancyhead[LE,RO]{\bfseries\thepage}
\fancyhead[LO]{\bfseries\rightmark}
\fancyhead[RE]{\bfseries\leftmark}
\fancypagestyle{plain}{
\fancyhead{} % get rid of headers
\renewcommand{\headrulewidth}{0pt} % and the line
}


%% Apalike hyphenation %%%
%\let\oldbibitem=\bibitem
%\renewcommand{\bibitem}[2][]{\oldbibitem[#1]{#2}\newline}

%%% Margins %%%
\voffset -1.04cm
\textheight 25cm
\hoffset -1in
\evensidemargin 2.5cm
\oddsidemargin 2.5cm
\textwidth 16cm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\textwidth16cm
%\textheight23cm
%\oddsidemargin0,5cm
%\evensidemargin0,5cm
\topmargin-1cm
%\parskip0,5cm
%\parindent0cm



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 'dedication' environment: To add a dedication paragraph at the start of book %
% Source: http://www.tug.org/pipermail/texhax/2010-June/015184.html            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newenvironment{dedication}
{
   \cleardoublepage
   \thispagestyle{empty}
   \vspace*{\stretch{1}}
   \hfill\begin{minipage}[t]{0.66\textwidth}
   \raggedright
}
{
   \end{minipage}
   \vspace*{\stretch{3}}
   \clearpage
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Chapter quote at the start of chapter        %
% Source: http://tex.stackexchange.com/a/53380 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\makeatletter
\renewcommand{\@chapapp}{}% Not necessary...
\newenvironment{chapquote}[2][2em]
  {\setlength{\@tempdima}{#1}%
   \def\chapquote@author{#2}%
   \parshape 1 \@tempdima \dimexpr\textwidth-2\@tempdima\relax%
   \itshape}
  {\par\normalfont\hfill--\ \chapquote@author\hspace*{\@tempdima}\par\bigskip}
\makeatother


% Babel ``Sommaire'' à la place de ``table des matières''
\renewcommand{\contentsname}{Sommaire}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% First page of book which contains 'stuff' like: %
%  - Book title, subtitle                         %
%  - Book author name                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Book's title and subtitle
\title{\Huge \textbf{Apprentissage dans les architectures cognitives}   \\ \huge contributions pour l'informatique et les neurosciences}
% Author
\author{\textsc{Emmanuel Daucé}}%\thanks{\url{www.example.com}}}


\begin{document}

\frontmatter
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Add a dedication paragraph to dedicate your book to someone %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{dedication}
Dedicated to Calvin and Hobbes.
\end{dedication}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Auto-generated table of contents, list of figures and list of tables %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\tableofcontents
\listoffigures
\listoftables

\mainmatter

\section*{Remerciements}
\begin{itemize}
\item A special word of thanks goes to Professor Don Knuth\footnote{\url{http://www-cs-faculty.stanford.edu/~uno/}} (for \TeX{}) and Leslie Lamport\footnote{\url{http://www.lamport.org/}} (for \LaTeX{}).
\item I'll also like to thank Gummi\footnote{\url{http://gummi.midnightcoding.org/}} developers and LaTeXila\footnote{\url{http://projects.gnome.org/latexila/}} development team for their awesome \LaTeX{} editors.
\item I'm deeply indebted my parents, colleagues and friends for their support and encouragement.
\end{itemize}
\mbox{}\\
%\mbox{}\\
\noindent Amber Jain \\
\noindent \url{http://amberj.devio.us/}

%%%%%%%%%%%%%%%%
% NEW CHAPTER! %
%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Introduction}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{chapquote}{Author's name, \textit{Source of this quote}}
``This is a quote and I don't know who said this.''
\end{chapquote}

% le modèle de Hopfield
% Qu'est-ce que le chaos?

% Qu'est-ce qu'un système apprenant



% Architectures de contrôle. Point de vue de la robotique. Automates embarqués. 

Quelle est la question?


% Philo
Créer du neuf à partir de rien.
Qu'est-ce que la nouveauté?
D'où vient l'information?

Potentialité et émergence. Notion d'historique. Constructivisme.
% Importance de l'activité intrinsèque
% Activité centrale flutuante, émergence, historique
% couplage sans fonction (corps sans organe)
% triptique : corps- société- organe (à différents niveaux) - organisme = société des organes
% analogie eonomique : composants - emploi - produit (composé)

% Ce que j'ai fait, quelles sont mes questions?

Les enjeux :

- Substrat apprenant (universel). 

- Aller au delà des modèles actuels de l'apprentissage (essentiellement behavioristes) en reprenant toute la structure conceptuelle de l'apprentissage. 


Aux sources de la subjectivité.

Dans ce rapport : orientation mecanises cognitifs $\rightarrow$ architectures logicielles.

D'un côté, le point de vue des sciences cognitives :
Agent incarné. Corps. Extension (du corps, du territoire) limitée. Ressources (computationnelles) limitées. 
Déplacement du corps et emploi du corps visant le retour à l'équilibre (dominé par des variables de type contrôle des apports énergétiques. 
Vient ensuite recherche d'abri, recherche de partenaires, etc...). 
Autonomie.

De l'autre, du point de vue du machine learning : extraterritorialité des données (peu de limite spatiale, ou absence d'extension spatiale). 
Ressources computationnelles distribuées (non localisées). Hétéronomie. L'accès aux ressources n'est pas un enjeu (dépend d'un agent extérieur).

Question : atteint-on une limite des rapprochements entre sciences cognitives et machine learning. Quels concepts sont-ils utiles pour construire des machines intelligentes. 
A-t-on besoin du hasard pour apprendre à gérer des actuateurs complexes (puisque les limites naturelles type code génétique n'existent pas).   

La plupart des besoins naturels sont non pertinents pour les machines (apports énergétiques, abri, partenaire).

Le tryptique Orientation-déplacement-emploi est inopérant dans le cadre ML.


Une architecture cognitive est alors une proposition de réalisation logicielle de ce cahier des charges (un logiciel capable de raisonner, se souvenir et faire des choix).
On distingue classiquement 3 approches pour la réalisation de telles architectures. 
\begin{enumerate}
 \item approche logico-mécanique (CALCUL)
 \item approche informationnelle / régulationnelle / décisionnelle (DECISION)
 \item approche  / pattern matching (APPRENTISSAGE)
\end{enumerate}

Historique :
\begin{itemize}
\item Les architectures de contrôle. Cybernetique.  Asservissement lineaire. Wiener.
\item Filtre de Kalman - Modele en miroir. Notion de bruit (d’etat et de mesure). Le bruit est l’expression la plus simple de l’autonomie d’un systeme.
\item Gibson / affordance (employabilité/actionnabilité). 
\item synergetique
\item les RN et l’apprentissage de la commande: régression (predicteur = classifieur ou regresseur) 
\item le RL (acteur/critique)
\item Robotique developpementale : Brooks / la subsumption.
\item l’espace de la tâche / des actuateurs et l’approche “point fixe” du contrôle
\item Mosaic
\item Friston
\end{itemize}


On regarde dans le détail ces trois approches avec un focus particulier sur l'apprentissage et l'autonomie. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Architectures cognitives}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Problématique}

Une architecture cognitive est un dispositif logiciel dont le but est de permettre à un appareil 
(disposant de capteurs et d'actuateurs) d'interagir de façon ``intelligente'' avec son environnement. 
Le concept de comportement intelligent reste bien sûr assez flou.
Ce problème d'une définition opérationnelle de l'intelligence a été posé au sortir de la deuxième guerre mondiale. 
Il s'agissait de construire un programme de recherche, une feuille de route détaillant les étapes nécessaires 
et suffisantes pour construire un dispositif artificiel intelligent.

Q: pourquoi parle-t-on d'architecture et pas de programme (ou de ``méta programme'')? Inclut le hardware. Architecture
est ici à mettre en relation avec architecture des calculateurs. l'approche RN consiste à revoir l'architecture meme du ``calculateur'' 
pour atteindre l'autonomie opérationnelle (``gouvernement de soi'').

D'un point de vue plus pratique, développer de véritables architectures cognitives, c'est ouvrir de nouveaux champs d'application variés:
\begin{itemize}
 \item déplacement de la charge cognitive (mais augmente la dépendance de l'homme au dispositif). Exemple de la démonstration automatique de théorèmes.
 \item personnalisation - accès à l'information (mais risque de ``flicage'' - problème de confidentialité)
 \item décision automatique / aide à la décision / conseil
 \item véhicules autonomes
 \item supplétion de l'homme pour les tâches ingrates ou dangereuses. 
 \item smart trucs. Environnement intelligent
 \item IHM immersives/empathiques. Repondeurs conviviaux. Avatars. 
 \item simulation économique et sociale
\end{itemize}

A un niveau très général, le but est de produire un dispositif dont les réponses s'apparenteraient dans la forme 
et dans le contenu à celles d'un être humain,
tout en reposant sur des opérations élémentaires issues d'un traitement logico-mécanique de l'information.
Cet objectif est exprimé de façon claire par le test de Turing \cite{TURING50}: un dispositif intelligent doit être capable 
de communiquer avec un être humain de manière naturelle, c'est à dire qu'il soit impossible pour l'opérateur humain,
en l'absence de contact visuel, 
de savoir s'il s'adresse à une machine ou à un être humain.
Cette approche n'est pas opérationnelle mais permet de tracer une frontières par exclusion. 
Un dispositif logiciel
n'est pas vu comme intelligent s'il ne passe pas le test de Turing.
Cette ``mesure'' est par nature imparfaite, puisque reposant in fine sur la subjectivité de l'observateur.
Différents contre-exemples peuvent d'ailleurs être trouvés dans lesquels des dispositifs
logico-mécaniques (machines) produisant des illusions, autrement dit sont tels que l'opérateur humain tend à 
leur attribuer des intentions qui n'y sont pas \cite{Braitenberg1986}. Attribuer des intentions est un biais perceptif humain.

Une approche plus opérationnelle consiste à décrire (lister) les compétences attendues de la part du logiciel.
Si on se réfère aux conceptions courantes de l'intelligence, 
il s'agit de décrire, modéliser mathématiquement et reproduire mécaniquement le sujet cognitif, capable de:
\begin{enumerate}
\item {\bf Calcul}. raisonner (agglomérer différents faits pour déduire des faits nouveaux - et/ou des réponses) - l'acuité (perspicacité) du raisonnement, 
c'est à dire la capacité à établir des faits nouveaux à partir de faisceaux d'indices (par déduction) - {\color{red} compatible paradigme behavioriste}
\item {\bf Mémoire}. Se rappeler (prendre en considération certains faits connus (acquis) en plus des faits imédiatement disponibles) - la memoire est liée à la notion d'``etat interne''. Croyance, Prior.
\item {\bf Plasticité}. Apprendre (intégrer de nouveaux faits, remettre en cause certains faits acquis) - {\color{red} compatible paradigme behavioriste}.
\item {\bf Décision}. Planifier et faire des choix, c'est à dire évaluer les bénéfices et les pertes attendus des actions ou des réponses produites.
\item etc.
\end{enumerate}

Dans ce cas (définition extensive de l'intelligence), plusieurs problèmes se posent. Il est (a) difficile de séparer les différents 
items et (b) difficile de fermer la liste. Selon le point de vue que l'on adopte, raisonner (estimer la véracité de certains faits) 
peut s'apparenter à décider (faire un choix). La mémoire, c'est à la fois se rappeler et intégrer des faits nouveaux.
Le raisonnement ne peut s'établir sur la base des observations immédiates, il doit intégrer des faits mémorisés etc. 
%Chacune de ces capacités (raisonner, stocker en mémoire, planifier,...) peut être implémentée
%dans certains contextes sans que le comportement du logiciel soit considéré comme intelligent au sens plein. 
%On pensera par exemple aux logiciels d'échec ou de go qui tendent à atteindre les capacités des experts humains,
%aux logiciels d'aide à la décision, aux pilotes automatiques, ... 
Enfin, il est difficile d'exclure de la liste certaines capacités comme l'intelligence pratique (sens
pratique, capacités opérationnelles, répertoire de comportements, agilité...)
ou encore l'intelligence émotionnelle, intelligence verbale, etc... qui ont reçu chacune des tentatives de définition. 

Cette approche (lister des compétences) est une approche typiquement réductionniste, consistant à découper un problème
en sous-problèmes pour mieux les analyser et les résoudre.
Malgré les nombreuses tentatives, il s'avère souvent que l'assemblage de briques
logicielles présentant des compétences élémentaires peine à aboutir à un système efficace. 
Dans le cas des système experts par exemple, le pur raisonnement sur les faits élémentaires aboutit rarement 
à une réponse réellement exploitable. %Les logiciels de traduction ou correction automatiques les plus efficaces 
%reposent sur les régularité statistiques, pas sur l'analyse de la structure de la phrase. 

\paragraph{Autonomisation des questions}

- question du langage

- question de l'apprentissage

- question du contrôle

- question du calcul

- etc...

L'identification de ces items : calcul - mémoire - plasticité - décision a permis d'aborder
ces problème en tant que tels, des problèmes vastes qui ont à eux seuls fondé des champs disciplinaires. 
Le calcul conduit aux calculateurs, aux processeurs, à l'informatique. 
La mémoire aux bases de données et à la recherche d'information.
La plasticité à l'apprentissage statistique (Machine learning).
La décision conduit à la recherche opérationnelle, et à la théorie du choix rationnel.
etc.

Au final, la recherche de l'automate ``intelligent'' semble être le terreau de nombreuses innovations 
dans les sciences de l'information au cours des 60 dernières années.
C'est bien en questionnant l'intelligence humaine et en cherchant à la reproduire
que les sciences de l'information semblent avancer.

Il semble également que plus les compétences des machines augmentent, plus elles semblent se rapprocher de l'intelligence,
plus nous voyons notre définition de l'intelligence évoluer/se transformer, comme un horizon qui s'éloigne sans cesse.
Ni les capacités de calcul symbolique, ni les capacités à jouer à des jeux de plateau, ni celle de fouiller dans des bases 
de données immenses,
ni bientôt celle de conduire une voiture ne semblent constituer des réalisations en relation suffisante avec l'intelligence
humaine.
Il semble y avoir une frontière infranchissable, une différence de nature entre l'intelligence machinique et l'intelligence humaine, 
entre hyperspécialisation et généricité, entre activité commandée et activité autonome, entre rigidité et adaptivité,
entre dématérialisation (virtualité) et incarnation, entre déterminisme et création etc.
Ces points seront abordés dans les prochains paragraphes.



\section{Les problèmes connus de la démarche réductionniste}

\subsection{Problème de la compétence universelle (ou et quand appliquer la bonne méthode)} 
Choix de la méthode. 
Versatilité.
Compétences multiples (séquentielle) vs. compétence intégrée (toutes les compétences en même temps).
Difficulté à traiter des environnements complexes. 
Le problème de la compétence globale a tendance à dégénérer en problème
du choix (de la bonne brique logicielle). Exemple des robots-jouets. Que faire dans une situation
qui n'a pas été prévue par le concepteur? Augmentation de la complexité. 
Chaque brique résout un problème spécifique. Tendance à l'``usine à gaz''.

ref : general proble solver (Simon - Newell).
Architecture SOAR (voir Wikipedia)

Le problème devient : produire quelque chose de neuf.
Le problème devient : l'intelligence, c'est atteindre un comportement adapté 
qui n'avait pas été prévu au départ par le concepteur. Capacité ``créative''. Capacité à faire face,
adaptivité.
Déplacement du problème : qu'est-ce qu'un comportement adapté?
Par extension. Peut-on définir un système dont le comportement s'adapte en permanence. 
A l'extrême : un système parfaitement vierge qui s'adapte aux conditions qui se présentent à lui.
 
Par opposition à l'approche réductionniste, nous 
considérerons ainsi dans la suite de ce document l'approche dite constructiviste, ou développementale, 
consistant à établir des règles de construction plutôt que des prescriptions.
On parle également de démarche ``bottom-up''.

Nécessité d'un principe fondateur.

\subsection{La question de l'autonomie}

Autonomie = s'affranchir de la commande.

Dans le domaine de la psychologie, l'émergence des sciences cognitives est venu en réaction au behaviorisme.
A l'origine, il s'agit de contester la description de l'activité du sujet comme simple courroie de transmission 
(un tableau de branchement) entre des stimuli et des réponses. Par opposition, il s'agit de décrire (proposer un modèle)
du sujet en tant qu'acteur. Notion d'agentivité (imputabilité de l'action).
%Toujours à ce niveau très général, une des notions clés de l'intelligence artificielle naissante est la notion d'agentivité, %autrement dit
%l'imputabilité de l'action. 
Un dispositif logico-mécanique pourrait être dit intelligent s'il était considéré comme responsable de ses actes, 
celui auquel on pourrait imputer les actions produites. 

Notes : la demarche behavioriste : Dressage = apprentissage ! Tableau de branchement (LUT). Le conditionnement opérant utilise le bruit créateur / l’exploration. 

Le ``noeud'' du problème. Imputabilité.
Les points 1, 2 et 3 peuvent être réalisés sans imputabilité. Seul 4 (choix) a des 

Principe de la boucle fermée. Différence entre notion d'autonomie (systèmes dynamiques) et systèmes autonomes au sens de la robotique.  

Dans le langage courant, on entend par ``intelligence'' la capacité à agir de façon appropriée en différentes circonstances, 
autrement dit de produire les réponses qui sont les plus à même de produire un bénéfice à l'agent.

Une première manière est de définir un dispositif cognitif par opposition à un dispositif ``commandé'', c'est à dire
capable de développer des comportements intelligents de façon autonome.

Recusation de la demarche behavioriste (et problème de l’agentivité). Plusieurs approches de l'autonomie (du point de vue des sciences expérimentales : expliquer le comportement variable d'un essai à l'autre autrement que par du bruit?):

1. Le délai. La délibération (Hebb).  ``délai'' entre le stimulus et la réponse (Hebb). Délibération interne. 

2. La boucle fermée. L’autonomie (sous l’angle des systemes dynamiques et sous l’angle des sciences sociales) vs l’heteronomie (la commande). Feedback et causalité circulaire. 
L’autonomie sous l’angle des variables de contrôle (ou paramètre d’ordre?). Il s’agit d’un paramètre endémique à réguler, comme l’acces aux biens materiels et/ou vitaux.
Perturbation et retour à l'équilibre. 

3. l'hystérèse. La résistance au changement. Mémoire à court terme. Etat interne. L’autonomie sous la forme elementaire de resonances de la fonction de transfert.

4. La plasticité. La mémoire, en tant que base de faits (LUT) et/ou de type interpolation (Hopfield) - lien avec Turing (ruban)? Lien entre interpolation et “predictive coding”.
Le pattern matching, les bases de filtres, les dictionnaires = traitement distribué. Gestalt (le tout est plus que la somme de ses parties). gestalt = “figures”.

5. Le bruit ``créateur'' - générateur de nouveauté. Exploration/exploitation. L’association d’idées (Hebb), l’itinerance. L’activité autonome, le “free-will”

Point de vue informatique : augmentation de l'autonomie des programmes au cours du temps. Décharge cognitive mais pas 
d'autonomie véritable. %Déplacement de la définition de l'intelligence (concept insaisissable).
La plupart des logiciels et les
applications utilisées dans la vie courante sont considérés comme ``non intelligents''. Ce sont des dispostifs ``commandés'', c'est à dire obéissant aux consignes 
et dont la réponse ne varie pas au cours du temps, ou d'une utilisation à l'autre. Ce comportement (conformité de la réponse à la consigne) est souhaitable dans la plupart
des cas. 
Toujours dans le domaine de la vie courante, est ``non intelligent'' tout ce qui est prévisible, ce que l'on peut manipuler, exploiter.

Il ressort : est intelligent ce qui n'est pas prévisible, 


\subsection{Problème de la représentation}

Tendance à faire reposer l'intelligence sur un modèle du monde. Plus le modèle est complet, exhaustif, 
meilleure sera la réponse. Exercer l'intelligence, ce serait simuler l'environnement, le monde extérieur,
pour estimer les conséquences attendues. Atteindre un but à long terme. 

Le modele du monde seul ne contient pas les actions produites par le sujet. La
simulation doit donc inclure un modele du monde et un modele du sujet agissant. Modèle du sujet se voyant agir. 
Modèle des motivations du sujet agissant???
Régression infinie...

Simulation des conséquences.
(explosion combinatoire évitée par des approches de type Q-learning)
Délibération.

Modèle de l'adversaire. Min-Max.

Mais : 

1. Nature des représentations. Quelle est la représentation adéquate. Représentation de type symbolique (qualitative / langagière)?
Représentation quantitative/extensive (copie du système extérieur). La nature du monde interieur est-elle in fine symbolique ou 
quantitative?

Le monde le l'information est intensif. Le monde extérieur est extensif. 

champ physique vs. champ neuronal???

2. Gibson. Monde caché / pb de la mesure. Ce qui est perçu n'est pas le monde en soi mais la relation du sujet au monde.
Les lignes verticales, les couleurs, sont des propriétés des récepteurs. La perception est (de plus) 
une relation entre les différentes sensations
(contraste, variation --> ordre 1).

Par extension : ce qui est perçu n'est pas l'outil en tant que tel, mais la relation du sujet à l'outil,
c'est à dire l'utilisabilité (= affordance).  

Le monde en soi n'est pas accessible, ou en tout cas est le résultat d'une reconstruction à partir des mesures.
Le monde en soi doit être inféré, il n'est pas donné en tant que tel (monde ``caché''). Variable latente.

Perception et non-sens.

3. Problème du monde ``en soi''. Constructivisme radical. Il n'y a pas de monde indépendamment du sujet. 
Seule la relation du sujet au monde est atteignable. Le reste est une spéculation. 
Tradition philosophique kantienne puis phénoménologique. Le monde est mis entre parenthèses.

Enaction. La relation du sujet au monde passe par des opérations autoritaires/créatives (le monde/la règle est constitué par décret). 
(par décret / innovation / création)
Gouvernance de l'environnement. Le sujet cherche à imposer sa vison, à façonner le monde (le soi) pour qu'il se conforme 
à l'idée qu'il s'en fait. La réfutation passe par le conflit (non conformité) - la rébellion de l'environnement contre 
la volonté d'assujetissement). 
Le monde (ou la perception) se construit dans le conflit / 
est le résultat d'un consensus (``c'est en se cognant qu'on apprend'').

\subsection{La question de l'incarnation}

Le ``retour au corps''. Brooks. 
Point de vue local. Répertoire moteur limité.
Améliorations par couches successives (empilement). Approche pratique/pragmatique. Viabilité.
Un circuit de régulation s'empile sur un autre circuit de régulation. Parallélisme.

\section{L'approche constructiviste (ou ``bottom-up'')}

Cette approche bottom-up était naturellement présente dès le début des sciences cognitives. 
Problème : plusieurs principes fondateurs en concurrence. 

Dans ce cas, plusieurs ``bases'' possibles : 
(1) logico-mécanique. {\bf Calculatoire}. Importance de la mémoire (ruban). Focus sur la dualité donnée-programme. Traitement (calculateur) ``digital''.
Historiquement la plus ancienne. Possibilité d'écrire 
dans le programme. Principalement notion de méta programme (programme constructeur de programme). 
Métaphore de l'ordinateur. Un ordinateur est doué de capacités de calcul, de mémoire et d'actuateurs.
L'IA revient ici à définir/décrire le méta programme. 

NOTION DE META-PROGRAMME

NOTION D'OPERATION

(2) cybernetique. {\bf Performative}. Focus sur l'action et l'imputabilité. {\bf Boucle fermée}. 
Question : qui commande? Principe de la régulation (cybernétique). Traitement (calculateur) ``analogique''. 
Importance des interactions mécaniques (approche située). Variables de contrôle. Zone de viabilité.
Comportement d'écart/retour à l'équilibre. Mais : calcul? mémoire? ODE. 
Développement de l'intelligence par ``subsumption'' et/ou empilement de mécanismes régulateurs (mesure / contre-mesure / contre-contre-mesure etc.). Régulation de variables internes.
Systémique et étude des relations entre les composants (``société des organes''). 

Dès l’origine, un des objectifs de la cybernetique est d’imiter le vivant. Notion de variable de controle et d’homeostasie. Erreur perceptive et correction de l’erreur perceptive. Grandeurs réelles (mécanistiques). Système de contrôle Newtonien (mécanique newtonienne).

(3) Focus sur la plasticité/sélection, {\bf Adaptative}. ``darwinisme''. Descente de gradient. Processus aveugle.
le traitement du signal + neuro-inspiré. Calcul distribué. Filtre. Auto-organisation. Population. 
Emergence. Attracteur. EDP? gestalt / attracteur / agencement 

De façon intéressante, on retrouve dans les 3 cas un raisonnement ``qui se mord la queue''. 



\subsection{Constructivisme logico-mécanique}

(CALCUL - CALCULABILITE)

Focus sur le langage et le traitement syntaxique - l'intelligence est manipulation de symboles - structuralisme - arbitraire du signe - tout est langage

Machine à états.  Manipulation de symboles. Connaissances et croyances. L'essentiel de l'effort a porté sur le traitement symbolique de l'information: 
la mémoire - la perception - les grammaires génératives - la logique formelle. Ces modèles cognitifs se focalisent sur la notion de croyance, c'est à dire 
d'état interne qui conditionne la réponse. (x, etat => y, LUT). Par extension, etat = connaissance, prior. Le prior peut biaiser la reponse. 

Mais (péché) traitement symbolique = examen séquentiel des faits. Peu de prise en compte de l'extension spatiale.

Le modèle de von Neumann (automate auto-reproducteur)

Le modèle de Varela-Maturana. Clôture. L'automate qui produit l'automate qui produit l'automate qui...

Le modèle de Chomsky


\subsection{Constructivisme performatif}

(FEEDBACK)

Systèmes dynamiques. (MECANIQUE) Notion d'équilibre dynamique (forces opposantes). Homéostasie. Wiener. Architectures de contrôle basées sur des variables de contrôle. Notion d'écart/erreur.  
L'agentivité se caractérise par le maintien actif de variables de contrôle à l'intérieur d'un certain intervalle. + Palo Alto. 
La contestation du paradigme behavioriste passe par la notion de contrôle ``reactif'' et d'ecart à l'equilibre. Notion de contrôleur/fonction de contrôle. On ne considère pas des 
``mappings'' stimulus-réponse discrets (x => y, LUT) mais des couples $(x_0,k)$ avec $y = k (x - x_0) $.    
Modèle inverse.  Architecture de contrôle et autonomie.

Importance du modèle de la robotique autonome comme application/implementaton la plus naturelle pour les architectures cognitives. 

\subsection{Constructivisme distributif}

(OPTIMISATION)
Basé sur l'optimisation d'une grandeur extensive (un champ). Espace vectoriel ou espace de Hilbert.

Soupe primitive auto-organisatrice.

Basé sur un substrat apprenant (expressivité limitée). 
L’expressivité du substrat conditionne le “monde perceptif” (au sens des categories et des relations de voisinage, 
d’identité, de similarité entre les stimuli sensoriels) (exemple : substrat 1D-2D de la carte de Kohonen). 

monde perceptif $\Leftrightarrow$ soi perceptif

Puissance d’expression. 

Rq : la demarche de Chomsky s’inscrit dans cette démarche (contraintes sur ce qui est exprimable). 
Notion de “reservoir”. Emergence = instanciation.


Approche statistique / particulaire. Représentation distribuée. Substrat. Boîte noire.


% L'émergence des neurosciences computationnelles


Plasticité + sparsité (parcimonie).

\subsection{Problèmes avec l'approche constructiviste}

Parfois risque du raisonnement circulaire. Auto-explicatif.
(exemple chez Friston : le comportement est la minimisation de l'énergie libre.
Chez Varela : la vie est l'autopoièse. 
Chez )
Les principes fondateurs ne sont pas prouvés.

Des définitions qui se tiennent ``au dessus du vide''.

Approches difficiles à falsifier.

Le feedback, la systémique sont des approches plus qualitatives que quantitatives. Risque de rester au niveau des principes.

D'un côté (calculabilité). Le programme qui interprète des programmes. Dualité donnée / programme. Récursivité.  

Feedback négatif. Réponse soumise à l'entrée qui est soumise à la réponse.

Récurrence. Hystérèse.

EM


\section{Architectures de contrôle}

Les architectures de contrôle sont des dispositifs logico-mécaniques destinés à produire des commandes via des effecteurs (actuateurs) à
partir d'un signal issu de ses capteurs.
La nature des effecteurs (ou des actuateurs) permet de distinguer les dispositifs purement logiciels 
des dispositifs électro-mécaniques ayant une action directe sur leur environnement via des 
dépacemements de masses. 

On assimilera ici  dispositif logiciel et contrôleur. 
On parlera de signal d'entrée pour qualifier les données analogiques ou digitales à traiter.     
On parlera de commande pour qualifier la réponse (analogique ou digitale) produite par le dispositif.

\subsection{Filtre de Kalman}

\subsection{Acteur-critique}

\subsection{Brooks}

\subsection{Mixture d'experts}


\section{Le cerveau comme modèle vs. le cerveau modélisé}

\subsection{Le cerveau comme modèle}

A différentes époques, les neurosciences se sont mises à l'agenda des sciences cognitives. 
C'est en puisant dans les connaisances biologiques
de leur époque que les sciences cognitives ont pu se renouveler.

- Les rendez-vous de l’IA et de la biologie. Reintroductions periodiques de la problematique de l’apprentissage et de la plasticité (horizon, perspective toujours repoussé dans les neurosciences et l’IA “classique”).

L'inspiration naturelle. Au cours de l'histoire des sciences cognitives, plusieurs rapprochements ont eu lieu avec les sciences du vivant et les neurosciences:

- Années 40 : modèle McCullogh et Pitts, plasticité de Hebb. Assemblée neuronale. Notion de représentation distribuée?

- Années 60 : modèles de la vision, le perceptron. Implémentation. Filtre. Classifieur. Feed-forward.

- Années 80 : modèle de Hopfield. Physique statistique. 

Analogie biologique. Calcul distribué. Le perceptron est à la base un modèle de la perception visuelle. 
Le perceptron apporte de nombreux concepts nouveaux qui vont s'avérer féconds pour les sciences cognitives.   

D'un côté, il appartient à double titre à une famille des modèles ``behavioristes''. Le perceptron est bien un tableau de branchement.
Sa règle de mise à jour repose sur des causalités stimulus-réponse.  
De l'autre, il introduit les concepts de filtres, de pattern matching et de calcul distribué, avec un fonctionnement qui diffère à  la fois 
du traitement logico-symbolique et du contrôle intensif/analogique.

Si le perceptron constitue un pas en arrière par rapport à certains prémisses des sciences cognitives (agentivité), 
il constitue néanmoins un pas en avant important 
puisqu'il produit un modèle généralisable de calcul distribué ET adaptatif 
(il propose une première implémentation décentralisée de l'apprentissage et de la plasticité).
On sort des approches logico-symboliques avec la prise en compte de l'organisation (extension) spatiale des stimuli.
(THERMODYNAMIQUE - PHYSIQUE STAT - TRAITEMENT DU SIGNAL - CHAMP)

Il s'agit d'un modèle nouveau qui ne tire ses prémisses ni du calcul symbolique centralisé (machine de Turing), ni de la théorie des systèmes dynamiques, mais
plutot de l'observation de l'organisation à l'oeuvre dans les premières couches du traitement visuel. L'apprentissage est bien guidé par la 
correction d'erreurs, mais agit dans l'espace des paramètres. 

Voir aussi Hubel et Wiesel.

Réseaux de neurones et boite noire.
Qui dit décentralisé dit boite noire difficile à interpréter...

L'apprentissage automatique s'est développé/autonomisé et se ramène souvent à des statistiques descriptives...
Dans ce cadre, un système apprenant est une machine à entrées-sorties, une fonction paramétrique, dont les paralètres on au choix : 
un degré de vraisemblance élevé, maximisent la séparation des données, ...
l'apprentissage devient un des branches de l'optimisation mathématique.

\paragraph{Orientation \--- Déplacement \--- Emploi}
Bases du contrôle moteur

\subsection{Le cerveau modélisé : les neurosciences computationnelles}

La metaphore de l’ordinateur (Von neumann). Neurosciences “computationnelles” (calculatoires). L’ordinateur effectue des calculs selon des recettes (algorithmes). Notion de processus. Programmabilité. Mémoire. (mais aucune autonomie).
Mais : obstacle du “test de Turing” : intelligence “machinique” (de type joueur d’échec). Problèmes (1) d’imputabilité et d’autonomie, (2) de raisonnement analogique (3) d’émotions et (4) reconnaissance de formes.

\paragraph{Modèles du neurone}

\paragraph{Plasticité}

\paragraph{Réseau et multi-scale}

connectivité fonctionnelle

\paragraph{Communication}

Le traitement du signal / la communication.

Canal de transmission (bruité). Bruit générateur.


La théorie de l'information : caractériser le caractère informatif (ou non) d'un message par son degré de prédictabilité. 
Problème : les deux extrêmes (information nulle, information maximale) sont inintéressants...
\--- Transmission de l'information \--- Emetteur et récepteur \--- débit. 

Théorie bayesienne 


\paragraph{Friston}

Ce qu’il faut retenir de Friston :

- un modèle en miroir. 

- les actuateurs sont une partie de l’env.

- perception = inference on states / learning = inference on parameters 

- l’action vient rectifier une erreur de prediction

- le reward est un prior sur la solution cherchée.

Rq : le concept d’energie libre est repris de Prigogine?.

Après relecture :

- Le terme d’energie libre se divise entre accuracy (distance entre les causes predites et les causes observées - innovation : idem Kalman et/ou Hidden Markov) et complexity (entropie du modele de la mesure).

- La structure de resolution est analogue à EM. 
E est l’inference des causes (par modele - ou mesure - inverse)
avec modele : estimation de x* par filtre de Kalman ou particulaire ou Viterbi 
avec identification du modele (recherche du modele generatif par inference - avec prior sur le nombre de causes...) 

- exemple typique = apprentissage d’un dictionnaire (base orthonormale ou non). Pb : explosion combinatoire si sequences temporelles ou etats vectoriels (ou combinaison d’etats). Probleme mal posé.
modele libre (absence de modele)

Action based. RL classique. Analogie etat caché / valeur (sortie du modele representationnel. L’etat interne ne represente pas l’etat du monde exterieur mais simplement l’avantage qu’on peut en attendre. Rq : le couple (actionneurs + environnement = systeme controllé = domaine extensif - masses en deplacements) est en general connu , c’est à dire qu’on a une connaissance complete. Le couple acteur + critique est l’agent - domaine intensif). Model free -  Policy gradient. Apprentissage direct du repertoire d’actions
(hierarchique) - Le prior est le posterior de la couche superieure (projection predictive en feed-back). La vraisemblance est le “matching” entre le signal de la couche inferieure et le filtre (feed-forward). “Bayesian surprise” - innovation = erreur perceptive

Le modele libre est distinct du modele search. Ca conduit à l’idée d’information mutuelle sans d’identité.  

M est l’identification (adaptative) du processus de mesure (ou du modele generatif ou du forward model). 

Etape qu’on identifie à l’apprentissage. Idem apprentissage du perceptron et des reseaux de neurones en general (supervisé)  : pattern matching, max likelihood, ...

Etape absente pour le filtre de Kalman ou les HMM. 

Friston propose une maniere originale d’augmenter la likelihood (action qui maximise la vraisemblance perceptive) = passage du côté “obscur” de l’”action-oriented” perception (consequence perceptive de l’action) $\Rightarrow$ agir, c’est mettre le monde à l’epreuve

En lien avec l’idée de sparsité $\Rightarrow$ minimiser la complexité en produisant des bases “sparse”

- La logique EM est fondamentalement circulaire. Se resout classiquement par iteration sequentielle. On peut egalement supposer une difference d’échelle temporelle entre processus E (rapide) et processus M (lent). 

-  Le RL peut etre vu comme un algo EM avec prior sur le modele (dans ce cas les causes sont essentiellement les actions). L’etape E est le calcul de la valeur des transitions (vraisemblance (posterior) de l’action etant donné la sensation). L’etape M est la mise à jour de la fonction de valeur (etant donné le reward - ici vu comme une mesure de la likelihood de la consequence perceptive). $\rightarrow$ consequence (ou inversion de l’argument): est vraisemblable un patron perceptif qui est recompensé - Tout ce qui n’est pas soumis à un mecanisme de recompense n’est pas perçu (perception ou non-sens - Cf. Merleau Ponty - Phénoménologie de la perception).

- F est la log vraisemblance marginale (sur posterior q(.) et mesure f(.)) qui se decompose en 2 termes : la divergence (surprise bayesienne - accuracy) servant à optimiser q(.) et la log vraisemblance conditionnelle (complexité) servant à optimiser f(.)

- La dualité accuracy / complexity peut etre vue comme le substrat d’autres dualités findamentales selon que l’on met l’accent sur l’un ou sur l’autre (exploration/exploitation), conservation /innovation etc… On peut imaginer un seuil d’innovation (== vigilance) qui permet de remettre en cause le posterior courant.

- Il y a un lien entre l’exigence de parcimonie et le principe de substrat à ressource/expressivité limitée. 

- Le predictive coding est une théorie des rôles complementaires des connexions feed-forward et feed-back + implementations mathematique du principe “perception = correction d’erreur”

 Karl Friston : ce qui est perçu est principalement l'ecart à la prediction (predictive coding).  Dynamical Causal modelling.
``{\emph Modern reformulations suggest
that both inference on states (that is, perception) and
inference on parameters (that is, learning) minimize
free energy (that is, minimize prediction error) and
serve to bound surprising exchanges with the world.}'' (Friston, 2010)



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Contributions}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Sont rassemblées dans cette section mes différentes contributions à la question des architectures cognitives. Mes travaux
se concentrent autour de la description d'architectures logicielles visant à favoriser l'autonomie opérationnelle, 
%construction d'un ``sujet'' artificiel, 
c'est à dire autorisant le programme à construire et autonomiser sa réponse vis à vis des sollicitations sensorielles de son
environnement.

Ces travaux se situent à l'interface de la branche “pattern matching” de l’IA (perceptron, RN, ART, Hopfield, ...) et des 
neurosciences. Nous travaillons sur des modèles qui ont à la fois vocation à développer des architectures logicielles ``universelles''
propres à capturer les régularités de leur environnement, et de l'autre à expliquer certaines propriétés du substrat neuronal (plasticité) 
et de la communication nerveuse. 
{\color{Violet} Le fil rouge : réseaux aléatoires. La fluctuation. Le bruit créateur. ET Le feedback positif.
Un cadre unique pour l'apprentissage et la plasticité. 
Essayer de construire un cadre conceptuel (ou de réexaminer des cadres conceptuels existants mais non explicités). }

{\color{red} La difficulté consiste à éclairer les méthodes de machine learning à partir de concepts issus des sciences cognitives. }


Dans la première section, nous regardons la question de substrat, en tant que matière première ou support de la communication (le hardware). 
En suivant l'analogie neuromimétique, nous étudions les conditions qui vont permettre à une population de calculateurs (les neurones) 
de s'organiser dynamiquement en activant ou désactivant sélectivement certains circuits.
Selon les caractéristiques des calculateurs élémentaires et les caractéristiques du patron de connectivité, 
les capacités d'expression (et par conséquent la nature de l'information produite ou transférée) seront différentes.
Nous considérons en particulier le problème de l'expressivité limitéee (tout substrat ne peut pas tout exprimer) 
et le principe de la capacité limitée (limitation du nombre de ``symboles'' ou de circuits ``effectifs'').
Nous terminons ce tour d'horizon avec une étude plus appliquée consistant à analyser le nombre et l'étendue de patrons spatio-temporels au
sein d'un réseau construit à partir d'une matrice de connectivité structurelle obtenue par une technique de tractographie chez l'humain.

La deuxième série de résultats est regroupée sous le thème de la ``subjectivité perceptive''. Les modèles présentés
explorent l'idée d'une autonomie partielle de la réponse logicielle à la commande. Vu sous l'angle neuromimétique, la 
subjectivité perceptive consiste d'une part à ignorer certaines entrées sensorielles, du fait de leur non-pertinence ou de leur 
non-conformité, et d'autre part à compléter certaines entrées sensorielles manquantes à l'aide de connaissances issues de l'expérience passée. 
Nous regardons plus particulièrement la question de l'apprentissage, ou comment les règles de plasticité synaptique (le méta-programme) vont permettre à certaines
stimulations sensorielles (désignées comme intéressantes) de ``creuser'' au sein du substrat un mode de réponse particulier (une ``résonance''),
cette résonance étant le support des interpolations perceptives futures. Nous regardons également en quoi ces architectures dites ``à feedback positif'' 
se distinguent du modèle classique du ``predictive coding'' organisé autour du principe du feedback négatif, et en particulier comment les premières
implémentent le comportement de  ``résistance au changement'' (ou persévération). 

La troisième section aborde la question plus globale de la formation des comportements moteurs. 
Nous commençons par rappeler certains principes et problèmes d'ordre général, comme la différence d'extensivité et d'expressivité du contrôleur et de son environnement.
Nous présentons ensuite un certain nombre de résultats ayant en commun le principe du contrôle en ``boucle fermée''.
Nous abordons ainsi successivement la question de la stabilisation et de la destabilisation des patrons d'interaction
vus comme des transitions entre activité autonome et activité commandée, et la question de l'activité autonome (chaos, bruits ``structurés'') pour l'implémentation
des mécanismes d'exploration dans le cadre de l'apprentissage par renforcement, sur divers substrats neuromimétiques. 
De manière plus appliquée, nous détaillons les principes d'une architecture de contrôle destinée à supplémenter des déficiences
motrices à partir de l'analyse de l'EEG de surface (interfaces cerveau-machines non-invasives).

La quatrième présente une série de résultats relatifs à des projets plus directement orientés vers la modélisation des mécanismes perceptifs et moteurs
tels qu'ils apparaissent dans les études neurophysiologiques et comportementales. 
L'orientation est une des modalités fondamentales de l'activité motrice, consistant à déplacer les organes récepteurs dans une direction qui optimise
leur exposition à des signaux d'intérêt. Nous étudions deux modalités de ce comportement d'orientation : d'une part l'orientation 
visuelle, et plus particulièrement la saccade oculaire, en tant que modèle de boucle sensori-motrice élémentaire, et de l'autre l'orientation 
temporelle, c'est à dire la capacité du sujet à concentrer ses ressources attentionnelles à un instant choisi dans le temps.


% DEA :
% - conditions de la destabilisation : etude des effets de petite taille. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     1      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Expressivité des substrats neuronaux}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Introduction}

Un substrat est un domaine matériel extensif, défini par des caractéristiques physiques homogènes, sujet à des flux de matière ou d'énergie,
et support d'une activité se traduisant par des changements d'état.
Derrière le terme substrat, nous entendrons ici principalement un domaine physique bien délimité, naturel (corps) ou artificiel (machine, circuit imprimé), 
capable de communication, c'est à dire capable de traiter des inputs (sensoriels) et de produire des outputs (déplacements, signaux).
Un modèle de substrat est un ensemble de variables d'état et une fonction de transition d'état censé traduire ces changement de la matière.

Nous nous intéressons ici à des substrats ``actifs'', qui dépassent par leurs propriétés de simples canaux de communication (la simple amplification)~: 
activité endogène, sélection des signaux, mémoire, plasticité...

Nous avons vu qu'un des problèmes posé par la construction d'architectures cognitives est celle de la non-exhaustivité: sur un hardware donné,
seul un nombre limité de faits peut être pris en compte, et un nombre limité de réponses produites.
L'universalité implique la mise en oeuvre de ressources indépendamment de la tâche (task-independent device). 
Le substrat doit au mieux exploiter ses ressources. 
Autrement dit, un programme à compétence universelle sera avant tout un programme qui devra gérer ses ressources de traitement pour les répartir au
mieux en fonction du nombre et de la complexité des tâches qui se présentent.

La question de l'expressivité d'un substrat tourne autour de cette notion de limitation~: analyser un certain nombre de
substrats (à mémoire limitée, à apports
d'énergie limités, à capacités de traitement limitées, soumis à du bruit, etc...) et estimer le nombre et le type d'opérations qu'ils sont capables de produire. 


Les réseaux de neurones naturels nous offrent un tel exemple de substrat universel, dans la mesure où, à 
travers l'ensemble des espèces animales, le même substrat (un réseau de neurones communiquant via des synapses) traite  
des signaux sensoriels variés et produit des réponses adaptées tout aussi variées. 
%{\color{Violet}
%A rappeler également : les niveaux de Marr : du substrat au modèle... et Turing bien sûr}

Par analogie aux substrats matériels, il existe un certain nombre de substrats \emph{logiciels} dans le domaine de l'apprentissage automatique. 
Tous les modèles de l'approche distribuée, tels qu'il se sont définis depuis le perceptron \cite{Rosen58}, reposent sur
une notion implicite de ressource limitée, qui se traduit en particulier par un ``choix'' effectué par le
concepteur sur le nombre de neurones à mettre dans la couche cachée.
Une définition quantitative populaire de l'expressivité d'un tel substrat est la dimension de Vapnik-Chervonenkis \cite{Vap95}, qui représente le caractère 
plus ou moins complexe d'un classifieur, en terme de nombre de pivots utilisé pour
séparer les données. 

L'encodage est le processus par lequel une classe a priori illimitée de signaux d'entrée sera traduit sous la forme d'un patron d'activité similaire,
ce patron étant le reflet, au sein du substrat, de cette classe de signaux. 
L'illustration la plus caractéristique d'un tel processus d'encodage est celle des réseaux de Kohonen \cite{KOHONEN} pour lesquels un nombre fixé de centres mobiles 
vont servir à encoder la distribution des entrées. Le substrat ``codant'' est caractérisé par un réseau de noeuds liés 
par des relations de voisinage. L'encodage permet ainsi de regrouper/traduire la similarité des données d'entrée
par le degré de voisinage des noeuds dont elles suscitent l'activation.  
On trouve dans cette même famille de réseaux constitué d'une couche de lecture et d'une couche d'encodage
le modèle ART de Grossberg \cite{ART98} qui ajoute à son modèle la possibilité de recrutement de
nouveaux noeuds (apportant à son substrat une expressivité non-bornée mais limitée par la dimension 
de la couche d'entrée).

Néanmoins, l'expressivité d'un substrat ne se limite pas au nombre de symboles. Elle repose également sur la nature (la ``qualité'')
des opérations (et des transformations) qui peuvent prendre place dans le substrat. 
Par exemple, l'existence d'un processus de pattern matching avec seuil conditionne la perception du monde sous forme de 
transitions brusques et de relaxations vers des attracteurs.
L'existence d'un modèle linéaire conditionne la perception du monde sous la forme de reponse linéaire (asservissement) à l'erreur de prédiction.
L'existence de delais conditionne la perception des causalités temporelles etc. 

L'exemple des réseaux de Hopfield \cite{Hop82} offre ainsi un éclairage différent sur l'expressivité d'un substrat en mettant en 
avant le caractère distribué (non-local) de l'activité. Contrairement à l'idée classique d'un noeud comme unité d'expression 
(par exemple unité de séparation dans le cas des classifieurs, unité de description dans le cas des cartes auto-organisées etc.), 
la capacité du substrat est vue sous l'angle du nombre
de patrons distribués (patterns) pouvant être obtenus en tant qu'état final (attracteur) atteint par le système
dynamique décrit par les poids (arêtes) du réseau.
La capacité s'exprime ici en nombre de \emph{modes} (configurations atteignables) et non en nombre de noeuds/vecteurs supports etc.
Si la capacité se trouve en principe augmentée
d'un facteur exponentiel ($2^N$ configurations distribuées possibles), la capacité effective est en pratique beaucoup plus réduite, 
se limitant à un nombre de modes (attracteurs) distincts en $O(N)$, c'est à dire de l'ordre du nombre de noeuds \cite{Amit1987,Tso88}.
La nature des opérations réalisables par le substrat est également différent puisqu'il s'agit principalement ici d'une
dynamique de relaxation adaptée à des opération de complétion et d'interpolation de données manquantes, implémentant un
mécanisme de mémoire dite ``auto-associative''. 
 
Le champ des possibilités d'expression varie fortement d'un modèle à l'autre. Ainsi, la théorie du 
``Champ neuronal dynamique'' \cite{Ama77B} décrit un substrat à support  
continu (un champ et non plus un réseau de noeuds discrets), dont la dynamique spatio-temporelle est décrite par un jeu
d'équation aux dérivées partielles. Ce modèle propose une description explicitement spatialisée
du substrat, et porte en lui une capacité de description (ou de reproduction) 
des caractéristiques spatiales et temporelles d'un environnement physique continu. Le nombre de modes possibles devient ici infini,
le substrat ayant la puissance du continu.

{\color{Violet} L'approche ``Multi-scale''}

L'approche ``Multi-échelle'' \cite{WILSON89,Varela2001} consiste à considérer un substrat dont les variables d'état évoluent (ou peuvent être décrites) 
selon différentes échelles spatiales et temporelles, chaque échelle de description étant explicative du comportement observé à l'échelle
supérieure (par des variables dites ``macroscopiques''). L'idée est ici encore d'établir des passerelles entre un substrat constitué d'éléments 
microscopique caractérisés par des processus rapides localisés et un environnement
physique caractérisé par des processus macroscopiques lents et spatialement étendus.

L'exemple des réseaux de neurones artificiels nous offre ainsi un équivalent logiciel de l'idée de substrat matériel
(tout réseau de neurone étant néanmoins en principe implémentable sous forme de hardware). J'utilise cet éclairage
pour passer en revue les  substrats neuro-inspirés étudiés dans le cadre de ma thèse et après,
sous l'angle donc de leurs capacités de traitement et d'expression.

Le fil rouge de notre approche est celui des réseaux de neurones à connectivité aléatoire, permettant de traiter de manière formelle et de quantifier 
le caractère extrêmement inhomogène des réseaux de neurones naturels~: variété des types cellulaires, variété des délais de
transmission, variété de la forme et du nombre d'arborisations synaptiques, etc.
A travers l'analyse de la distribution des patrons de connexions, de la distribution leur intensité, de la distribution des délais associés,
nous posons la question du rôle de ces distributions dans la formation de patrons d'activité (ou modes) variés, supports potentiels
d'opérations cognitives. 

Cette étude a été entamée au milieu des années 90 au sein d'un petit groupe animé par Manuel Samuelidès, professeur à Supaéro, et Bernard Doyon, chercheur
à l'INSERM. Les premiers réssultats portaient sur l'étude de réseaux aléatoires très simples, dont le patron de connexion
était issu d'un tirage gaussien centré. L'étude du système dynamique issu de ce patron de connexion met en évidence
un comportement de route vers le chaos par quasi-périodicité \cite{Doyon1993,CESSAC94}, dont le comportement à large échelle (limite
``thermodynamique'') s'apparente à un processus aléatoire gaussien \cite{Ces95}.
C'est au sein de cette équipe que j'ai effectué mon stage de DEA \cite{Dau95} ainsi que ma thèse \cite{Dau00}.

L'approche que je mets en avant dans cette section 
est donc l'analyse des capacités d'un réseau de neurones en tant que support potentiel d'opérations cognitives. 
Dans ces différentes études, nous n'abordons pas la question de la plasticité, ne regardons pas les questions de communication ou de mémoire
comme l'encodage ou le traitement effectif des signaux. 
Notre approche se concentre sur la notion de régime dynamique et d'\emph{attracteurs}. L'idée principale est que notre substrat
neuronal doit être capable d'exprimer différents ``modes'' de fonctionnement. Ces modes se traduisent soit par des régimes dynamiques
variés (synchrone/asynchrone, point fixe/périodique/chaos), soit par des répartitions spatiales différenciées, appelés ``patrons d'activité''.
Nous étudions ainsi le nombre et la variété de ces patrons d'activité, leur stabilité, leur répartition et leur résistance aux perturbations.

{\color{Violet}

Expressivité du substrat (discret/réel, dimension, richesse du comportement intrinsèque).  

Extensivité/intensivité

Echelles temporelles


Typologie :

- existence (ou non) de l’etat “je ne sais pas” (OFF state). Resistance au changement (hysteresis). ODE.

- prise en compte (ou non) des dépendances temporelles. 


{\bf computation/traitement du signal basé sur la pattern matching (filtres) et non sur un traitement intensif/analogique 
(architectures de contrôle). Glissement de l'espace des actions à l'espace des paramètres.}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     1.1      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Réseaux aléatoires équilibrés}

Les premières études auxquelles j'ai participé portaient sur l'étude des transitions de phase dans les réseaux de neurones
aléatoires. 
La notion d'aléa ne porte pas sur la dynamique d'état mais sur le patron de connexions du réseau. 
On parle de bruit ``figé'' dans les connexions (``quenched disorder'').
Il s'agit d'un système dynamique déterministe, constitué de $N$ neurones, défini par la matrice des 
couplages $J = \{J_{i,j}\}_{i \in 1..N,j \in 1..N}$ où chaque lien $J_{ij}$ est donc issu d'un tirage aléatoire indépendant.

L'indépendance entre les différents liens est une caractéristique importante, qui permet d'analyser le comportement du modèle 
à la limite des grandes tailles, c'est à dire en faisant tendre la taille $N$ vers l'infini. Avec un \emph{scaling} des poids approprié 
(espérance, variance de la loi de tirage initial en $O(\frac{1}{N}$)), on peut montrer que la dynamique (déterministe) tend à la limite thermodynamique 
vers un processus aléatoire, la corrélation entre les noeuds tendant vers 0. 

{\color{Violet} activité intrinsèque}

Les premières études sur ce  type de modèle avaient été faites par Sompolinsky \cite{Som88} sur un système dynamique continu. 
L'analyse d'une variante à temps
discret avait été proposée par Cessac et Samuelidès \cite{Ces94}. La démonstration de cette propriété (dite de ``chaos local'') a été  
formellement achebvée, dans le cas discret, par Moynot et Samuelides \cite{Moy00a} en 2000.

Le comportement d'une classe de réseaux (l'ensemble des réseaux définis par la même loi de tirage initial) peut être décrit à la limite thermodynamique par 
des équations dites de ``champ moyen''. Ces équations définissent le processus aléatoire limite, autrement dit la dynamique temporelle de grandeurs caractéristiques comme l'activité moyenne, 
le moments d'ordre 2 et la covariance dans le temps \cite{Ces95}. 
Les équations de champ moyen offrent ainsi une description ``macroscopiques'' de l'activité d'un réseau,
représentative de l'activité qu'on peut attendre dans un réseau de taille finie issu d'un tirage particulier, et 
constituent de fait un cadre d'analyse adapté à une approche ``multi-échelles''.

Il est intéressant de constater que le processus stochastique limite, tel que décrit par les équations de champ moyen, 
a une traduction à taille finie
sous la forme d'une activité de type chaos déterministe. L'existence d'un 
paramètre d'ordre (le gain de la fonction de transfert des neurones) permet de reproduire, dans ces réseaux aléatoires, 
un  comportement générique de destabilisation, appelé route vers le chaos par ``quasi-périodicité'' \cite{Berger1988,Doyon1993}.
L'existence d'une telle frontière entre l'ordre et le chaos est également prouvée à la limite thermodynamique, mais dans ce
cas la transition se fait brutalement, avec un passage discret d'un processus de type point fixe à un processus stochastique \cite{Ces95}.
Cette frontière entre ordre et chaos est par principe intéressante puisqu'elle indique le lieu
où la variabilité de la dynamique, et donc potentiellement l'expressivité du réseau est la plus importante. 

En collaboration avec Moynot, Samuelides et Pinaud \cite{Dau99A,dauce01a}, j'ai travaillé sur la définition et 
l'étude du comportement à taille finie d'un modèle de réseau de neurones aléatoire (RNA) multi-populations.

%{\bf Daucé, E., Moynot, O., Pinaud, O., Samuelides, M. and Doyon, B. (1999) Mean Field Equations reveal synchronisation in a 2-population neural network model, proc. of the 7th European Symposium On Artificial Neural Networks (ESANN'99), Verleysen, M. ed.:7-12, April 21-23, Bruges, Belgium}

%{\bf Daucé, E., Moynot, O., Pinaud, O. and Samuelides, M. (2001) Mean Field Theory and Synchronization in Random Recurrent Neural Networks, Neural Processing Letters 14:115-126}

Le point de départ consistait à modéliser et reproduire certains comportements observés dans les 
réseaux de neurones naturels composés d'une population de neurones excitateurs et d'une population de neurones inhibiteurs.
Cette classe de réseaux de neurones (constitués d'une population de noeuds inhibiteurs et d'une population de noeuds excitateurs)
est appelé réseau de neurones ``équilibré'' (balanced neural networks), l'équilibre se référant à l'idée d'équilibre
dynamique entre deux forces opposantes. La dynamique du réseau est amenée à converger vers un point d'équilibre
traduisant localement (et globalement) le ``poids'' des deux influences. Une configuration des poids se traduisant
par une activité endogène soutenue 
traduit une domination de l'influence excitatrice. 
A l'inverse, une configuration où l'activité intrinsèque disparait après un certain temps 
traduit une domination de l'activité inhibitrice.
Comme dans le cas des réseaux aléatoires simples, il existe un paramètre d'ordre correspondant au rapport entre l'influence 
excitatrice et l'influence inhibitrice. De manière intéressante, une grande variété de comportements dynamiques peuvent être observés
à la frontière, et entre l'extinction et l'activité soutenue, comme les oscillations synchronisées \cite{brunel00} et/ou le chaos \cite{Van98}. 

L'étude que nous avons présentée \cite{Dau99A,dauce01a} étudie le comportement d'un réseau équilibré de ce type. Ce papier 
étend pour la première fois le modèle de champ moyen pour le cas des réseaux à connectivité aléatoire à populations multiples
(auquel cas les tirages aléatoires sont effectués sur des ``faisceaux d'axones'' reliant une population de neurones $p \in 1..K$ à une
population de neurones $q \in 1..K$, où $K$ est le nombre de populations).
Ce modèle renouvelle l'approche large-échelle classique \cite{WILSON89} en prenant en compte l'hétérogénéité des faisceaux
d'axones reliant différentes régions du réseau.  
Il sert de base à la définition d'architectures neuronales fondées sur des 
substrats à connectivité aléatoire. 

{\color{Violet}
[Multi-pop = base pour l'approche multi-échelle. Construction / architecture neuronale. Prise en compte de l'hétérogénéité.]
Multi-pop = travail de master d'O Pinaud.
Demonstration champ moyen = O Moynot (avec généralisation à la connectivité diluée)}

L'étude numérique proposée dans le papier fixe le rapport excitation/inhibition à $\frac{1}{2}$,
ce qui correspond à un régime de faible activité \cite{Amit1989}. 
Nous étudions le rôle contrasté de deux paramètres d'ordre. 
Le premier paramètre, $J$, représente l'amplification du signal. L'augmentation
continue de ce paramètre tend à produire une bifurcation entre un régime simple (point fixe) et une activité 
complexe (de type chaotique) comme précédemment.
Un second paramètre, nommé $d$, représente l'inverse du \emph{coefficient de variation} des liens, autrement dit le 
degré d'homogénéite. Augmenter ce paramètre tend à rendre les poids plus homogènes. De manière intéressante, 
l'augmentation continue de ce second paramètre (augmentation de l'``ordre'') produit une transition 
entre un régime stationnaire et un régime non-stationnaire périodique. Nous mettons en évidence une carte
de bifurcation à 4 régions, comprenant un régime stationnaire de point fixe, un régime stationnaire complexe,
un régime d'oscillations simple, et un régime d'oscillations complexes analogue à processus stochastique cyclostationnaire,
ce dernier régime étant à notre connaissance mis en évidence pour la première fois dans ce type de réseaux.

Notre étude a donc ouvert la voie à l'étude multi-population systématique des réseaux de neurones à connectivité aléatoire \cite{Faugeras2009,Cabana2013} 

{\color{Violet}
[O. Faugeras, J. Touboul, B. Cessac, “A constructive mean field analysis of multi population neural networks with random synaptic weights and stochastic inputs”, Front. Comput. Neurosci. (2009) 3:1.

et aussi 
 
Large Deviations, Dynamics and Phase Transitions in Large Stochastic and Disordered Neural Networks
Tanguy Cabana1 and Jonathan Touboul (2013)

La question de l'homogénéité/hétérogénéité est revenue à l'ordre du jour. Plusieurs papiers récents bla bla...}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     1.2      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Réservoir}

Un des intérêts principaux des réseaux à connectivité aléatoire est leur capacité à générer des dynamiques complexes
endogènes (donc sans stimulation extérieure). Ces dynamiques, bien que reposant sur des équations déterministes,
se comportent comme des processus stochastique indépendants sur chaque neurone. Ce comportement n'est pourtant pas analogue
à un simple bruit passif. 

Une manière simple de caractériser le comportement non-linéaire (ou critique) d'une population de neurones consiste à introduire de petites perturbations
dans la dynamique du réseau. 
Une étude proposée dans le 3ème chapitre de l'ouvrage que nous avons co-dirigé avec Agnès Guillot \cite{Beslon2002} illustre bien le propos.
Cette étude porte sur le modèle le plus simple, un réseau récurrent aléatoire comportant une seule population. Le paramètre d'amplification
choisi place le réseau dans une région chaotique, proche de la transition vers le cycle limite.  
Le réseau est soumis à une stimulation extérieure quasi stationnaire, évoluant à une vitesse très lente par rapport à la vitesse de 
mise à jour du réseau. Une succession de régimes dynamiques distincts, séparés par des transitions brusques, est mis en évidence.
Chaque régime est caractérisé par un patron d'activité différent, qui se manifeste par la présence de fréquences caractéristiques
distinctes dans le spectre de Fourier du signal moyen.  

Une autre étude, présente dans mon manuscrit de thèse \cite{Dau00}, développe l'analyse spatio-temporelle des patrons d'activité de type cycle limite
ou chaos léger.
L'existence d'une chaîne d'activation spontanée (synfire chain \cite{ABELES91}) est mise en évidence par analyse de la matrice de covariance des signaux individuels. 
Différents modes (patrons d'activation spatio-temporels) se développent spontanément lorsque le réseau est soumis à des entrées statiques différentes \cite{Dau01b}.
Enfin, l'analyse de la réponse du réseau à une stimulation périodique indique une ``bande passante'' de quelques unités temporelles, le réseau étant capable 
de ``capturer'' (et donc d'amplifier) des signaux dont la période varie entre 2 et 10\--12 unités de temps
(autrement dit à sélectionner un mode dynamique périodique interne compatible avec la période imposée) \cite{Dau01b}.
Le comportements spontané des réseaux récurrents aléatoires est par ailleurs à la base du mécanisme de perception par feedback positif
présentés dans la section \ref{sec:FPos}. 

L'intérêt du comportement spontané des réseaux récurrents à connectivité aléatoires a été largement confirmé depuis. 
Une étude plus systématique de la réponse linéaire dans les réseaux récurrents \cite{Cessac2007} met en évidence 
l'existence de modes et de résonances extrêmement variés lorsque le signal est applique sur un seul noeud du réseau (micro-stimulation). 
Les modèles de ``réservoir
computing'' proposés par l'équipe de Wolfgang Maas \cite{Maass2002} reposent sur le même principe : un réseau de neurones aléatoire récurrent soumis à un signal
spatio-temporel est capable de conserver une mémoire de quelques unités de temps utilisables pour produire des classifieurs sensibles
au contexte temporel.

{\color{Violet} Image du papillon-chenille.}

Ce modèle de réseau à connexions aléatoire offre un exemple de substrat dont la caractéristique principale est la \emph{capture dynamique}, reposant
sur des transformations morphologiques des patrons d'activités (changements des distributions spatiales et temporelles des activités). Bien que construits sur
un tirage aléatoire arbitraire, ils offrent donc un bon support pour le traitement (et la transformation) des signaux temporels. 
Faire reposer le traitement sur un tirage arbitraire rejoint d'ailleurs un certain nombre de techniques de plongement (ou projection) aléatoires
utilisées en apprentissage automatique, tels le ``compressive sensing'' \cite{Baraniuk2007} ou l'architecture ``extreme learning'' \cite{Huang2006}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     1.3      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Codage topographique}

La vocation des modèles de champ neuronal \cite{Ama77B} est principalement la modélisation d'un substrat neuronal spatialisé vu à ``large échelle'' 
(continuum d'activité sur la surface corticale).
Ce modèle partage avec le réseau de Hopfield la capacité à conserver et entretenir 
une activité autonome indépendamment de son signal d'entrée. 
Il implémente néanmoins des opérations tout à fait spécifiques et intéressantes du point de vue computationnel. 
Un champ neuronal implémente simultanément une ``mémoire de travail'' (capacité à conserver la trace d'une stimulation passée), et 
un mécanisme de traitement (ici résumé à quelques opérations simples : émergence, extinction, fusion, poursuite) \cite{Schoner95}. 
La combinaison de ces deux compétences (mémoire et calcul)
au sein d'une architecture unique fait en principe du neural field un environnement computationnel complet \cite{Siegelmann1999,Maclennan1999,Potthast2013}. 

La question adressée par le modèle publié en 2004 \cite{Dau04} est celle de l'implémentation de ce modèle sur un support composé
d'unités discrètes.
%, comme l'activité dite ``persistante'' ainsi qu'une bonne sensibilité au signal d'entrée (switch). 
Sur les modèles jusqu'alors proposés, dans un cas l'activité focale était soit uniquement réactive \cite{Han96},  
dans l'autre cas,
l'activité persistante reposait sur un mécanisme de bistabilité cellulaire \cite{Cam98} ou encore sur une
plasticité synaptique à court terme \cite{Com00}. 
Notre modèle est une des premières implémentations d'un champ neuronal sur support discret reposant sur des mécanismes de réseau
uniquement.

Le papier étend le modèle récurrent aléatoire \cite{Dau01a} à des connectivités
plus complexes, incluant des délais variables et les connexions dépendantes de la distance. 
Un des apports du papier est de montrer 
la stabilité de certains indicateurs (comme le niveau de réponse moyen) à travers les modèles. 
Par exemple, l'introduction de délais différents entre les populations excitatrices et les populations inhibitrices conduit 
à des changements qualitatifs (régime d'oscillations lentes synchronisées) mais non quantitatif (même réponse
moyenne). 

L'introduction d'une connectivité dépendante de la distance opère un changement plus radical, 
puisque l'hypothèse fondatrice du modèle (indépendance des tirages) n'est plus vérifiée, 
et donc l'hypothèse de chaos local (indépendance des activités) n'est plus valide.
Les unités neuronales de chaque population reçoivent des coordonnées spatiales (ici prises uniformément sur l'intervale $[-\pi,\pi]$).
Le tirage des poids synaptiques devient dépendant de la distance qui sépare deux unités.
La valeur moyenne d'un poids est identique à celle du modèle précédent, 
mais les noeuds les plus proches ont en espérance une valeur
plus forte, et les noeuds les plus éloignés une valeur plus faible 
(la distribution des poids synaptiques repose sur le produit
entre la distribution uniforme initiale et un noyau gaussien conservatif).
Le mécanisme du champ neuronal, qui se caractérise par une connectivité majoritairement excitatrice à 
courte distance, et inhibitrice à longue distance, est implémenté à l'aide de ces noyaux gaussiens 
tels que le rayon du noyau des liens excitateurs est plus faible que celui des liens inhibiteurs.  

Le papier montre alors que les propriétés des réseaux aléatoires récurrents et celles des champs neuronaux s'additionnent dans ce modèle,
puisqu'on peut mettre en évidence sur ce substrat la présence simultanée d'une activité de fond chaotique,
de grandes oscillations lentes et de foyers d'activité de type champ neuronal. 
Comme dans le cas du champ neuronal, l'activité persistante repose sur l'activité excitatrice locale, avec 
un effet de lissage lié à l'hétérogénéité des connexions. Les oscillations lentes reposent comme précédemment
l'existence de délais différenciés. Ce sont ces oscillations qui donnent au substrat 
la capacité de répondre à des changements de faible amplitude (augmentent donc la sensibilité 
du substrat au signal d'entrée). Il en résulte une implémentation d'un champ neuronal 
sur un substrat composé d'unités neuronales discrètes.

De manière plus générale, ce modèle nous fournit un premier exemple, dans le cadre des réseaux récurrents aléatoires,
de l'effet de mémoire produit par une boucle de rétroaction positive. La rétroaction positive, et les effets de mémoire qu'elle
permet, sont probablement un composant essentiel des opérations réalisées dans le cerveau \cite{Compte2006}.    
Ce mécanisme  dit de ``réverbération'' \cite{Heb49} a été modélisé de longue date \cite{Wilson1972, Ama77B, Hop82},
mais reste peu utilisé (sous-utilisé?) dans le domaine des architectures cognitives. On note quand même 
un contexte applicatif proposé par G. Schöner en robotique mobile \cite{Schoner95}.

A mon sens, le manque de développements applicatifs vient probablement d'une difficulté pratique à doser le
seuil de réponse aux changements de l'environnement. Avec un seuil de réponse trop élevé, l'effet de mémoire s'avanouit. Avec 
un seuil de réponse trop faible, le réseau devient résistant au changement (autrement dit ignore le signal d'entrée).
Le réglage de ce seuil dépend du modèle choisi et du problème posé.
Plus généralement, les mécanismes de feedback positif introduisent une dose d'autonomie dans les architectures neuronales, 
rendant la réponse du réseau dépendante du contexte. Cet effet de réponse contextuelle (ou de mémoire) offre bien sûr une plus
grande panoplie de comportements, mais augmente la difficulté d'analyse du controleur (cadre non-Makovien),
et donc de la connaissance des risques de dysfonctionnement. Cette difficulté est encore augmentée lorsqu'on introduit
un mécanisme de plasticité, ce que nous verrons dans la prochaine partie \ref{sec:FPos}.

Notre modèle propose une passerelle simple entre les modèles de champ neuronal continus et de
réseaux de neurones à état et à temps discret. 
Il s'étend facilement à des réseaux de neurones intègre-et-tire (non publié), avec des
%L'activité produite repose néanmoins essentiellement sur la fréquence de tir des neurones (et non sur l'ordre de tir
%ou la co-activation). Les propriétés obtenues ne sont donc 
propriétés peu différentes qualitativement de celles qu'on 
obtient avec des modèles à fréquence de décharge.
Ce modèle a été utilisé en tant que couche perceptive dans des architectures de contrôle \cite{Dau04b,Dau07}. 
D'autres modèles visant une plus grande fidélité aux processus biologiques 
ont étudié l'effet de délais variables et de patrons de connexion hétérogènes (voir par exemple \cite{Roxin2005}),
et plus généralement l'étude de l'interaction entre délais variables, topographie et dynamique reste un sujet d'actualité 
en neurosciences computationnelles \cite{Voges2012,Lundqvist2012}.


{\color{Violet}{\bf 2007}

- MAPS : idée de codage topographique (autrement dit Kernel encoding). 

- projecion focale vs. projection laterale

}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     1.4      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Extension aux populations de neurones à spikes}

Le signal produit par les neurones biologiques n'est pas une grandeur continue. Les neurones
ont un comportement fortement non-linéaire, caractérisé par le franchissement d'un seuil d'activation.
La cellule neuronale intègre les multiples potentiels post-synaptiques issus de ses synapses afférentes
et émet un bref potentiel d'action lorsque le potentiel total atteint le seuil d'activation (on
dit que la membrane se dépolarise).
Après une brève période de repos (``remise à zéro''), le neurone recommence à intégrer les signaux entrants etc.
Le système nerveux est donc caractérisé par l'émission et la réception de signaux discrets, qui présentent 
à première vue une certaine analogie avec les signaux numériques, 
à ceci près qu'il n'existe pas d'horloge centrale pour cadencer les opérations.
C'est ce caractère discret des opérations neuronales qui avait inspiré les premiers modèles de neurones,
au sein desquels les unités neuronales se comportaient comme des portes logiques \cite{MCu43}, par analogie avec 
les circuits logiques des architectures informatiques.

Les neurones biologiques sont également caractérisés par le type de neurotransmetteurs qu'ils émettent
au niveau des synapses de leur arborisation terminale. On distingue les neurones inhibiteurs produisant des
synapses GABAergiques et les neurones excitateurs produisant des synapses excitatrices variées 
(glutamate, acétylcholine, dopamine, ...). 
L'action synaptique inhibitrice est une ``contre-action'' qui vient s'opposer
à l'effet des synapses excitatrices.
L'action et la contre-action, c'est à dire l'équilibre dynamique entre
deux forces opposées, est au coeur des opérations réalisées par le système nerveux. 

Les neurones à potentiel d'action disposent en principe d'une expressivité 
supérieure à celle des neurones à fréquence de décharge \cite{Izh06}.
Ils offrent des possibilités d'opérations (tels le codage par rang, la polychronisation,...)
ainsi qu'un support pour un traitement parallèle distribué (``multiplexage'') par décalage de phase
ou par bande de fréquences [CITATIONS].
Un des enjeux connus est la possibilité d'émuler un mécanisme de synchronisation/coordination 
longue distance supposé à l'oeuvre dans le cerveau pour l'integration multimodale \cite{Rod99}.

Le travail sur les neurones à impulsion a été initié dans le cadre du programme de collaboration de l'ACI en neurosciences
intégratives et computationnelles ``temps et cerveau'', projet ``DYNN'' 
(Dynamique des réseaux de neurones artificiels
biologiquement plausibles) \cite{Sam07}.
Une des questions au coeur de ce projet était la possibilité d'étendre l'analyse de champ moyen 
des réseaux  récurrents aléatoires au cas des neurones à spikes, ainsi bien sûr que d'exploiter les
possibilités dynamiques de ces modèles pour l'apprentissage et le contrôle.
Les changements principaux sont donc : sortie discrète (spikes), mise à jour par equation différentielle 
(et non plus équation aux différences finies), prise en compte explicite des délais et des constantes temporelles,
spécialisation des neurones (excitation/inhibition).
Ce projet collaboratif a abouti à la publication d'un numéro spécial dans la revue ``European Physical Journal \---
Special Topics'' \cite{ces07b}.

Mes contributions dans ce domaine portent sur l'étude des transferts d'échelle 
entre neurones fréquentiels et neurones à potentiels d'action, à la définition de 
patrons de connectivité séparant clairement neurones excitateurs et neurones inhibiteurs,
et à la mise en place d'un formalisme architectural indépendant des modèles.
Le principe qui, dans notre cas, unifie l'approche des neurones à sortie continue 
et des neurones à sortie discrète est présenté dans \cite{Dau07}. Il repose sur 
un modèle de neurone intègre-et-tire normalisé à résolution temporelle variable. Le passage du neurone 
discret ``à fuite'' au neurones binaires (McCullogh et Pitts), puis au neurone à sortie continue est obtenu 
par simple variation du pas d'intégration du schéma d'Euler de l'équation différentielle qui définit le neurone.
Il en ressort une unification des modèles à travers les échelles temporelles où les neurones 
intègre-et-tire représentent une résolution de l'ordre de la milliseconde, les neurones binaires une résolution
de l'ordre de la dizaine de millisecondes et les neurones à sortie continue une résolution de l'ordre de la centaine
de millisecondes.

Les architectures multi-populations ont été approfondies à partir de l'approche par ``faisceaux d'axones'', indépendants
de la définition spatiale. Les divers paramètres d'ordre en jeu, à savoir le taux d'amplification, le coefficient de variation, 
le délai moyen participent à définir des architectures fonctionnelles diversifiées définies principalement par le nombre 
et la fonction des populations en jeu, permettant de tester le comportement de certaines architectures fonctionnelles.  
D'autres paramètres, comme la densité de connexion, le poids synaptique moyen etc.  apparaissent conditionnés aux  paramètres structurels principaux.

Les architectures à populations excitatrices et inhibitrices ``équilibrées'' présentent, 
dans les mêmes gammes de paramètres que précédemment, 
des comportements de population très similaires.
Les régimes d'oscillations lentes synchronisées
se retrouvent également dans ces modèles. 
Des transitions de phase sont observables entre
différents régimes dynamiques sous l'effet de la variation de certains paramètres d'ordre, 
ou sous l'effet de la plasticité synaptique \cite{Hen08,Hen08B,Henry09}. 

Manipuler des architectires neuronales à différentes résolutions spatiales et temporelles permet d'estimer les éléments
structurels communs aux différents modèles indépendamment du niveau de résolution (et, 
de façon complémentaire, d'identifier les éléments structurels spécifiques à un niveau de 
résolution spatial ou temporel donné, et/ou d'estimer les limites d'expressivité des modèles 
à basse résolution). 
Ainsi, nous avons pu confirmer le caractère \emph{non spécifique} des régimes d'oscillations lentes,
qui n'apparaissent pas conditionnés 
au type de cellule utilisée (à sortie discrète ou continue), mais reposent plutôt 
sur les paramètres et effets de réseau, comme les fréquences moyennes, le taux d'amplification et les délais de transmission entre les différentes populations.
Les effets de réseau (de ``masses'' neuronales) apparaissent prédominants dans les réseaux récurrents aléatoires et
les simulations à ``haute résolution'' viennent souvent confirmer des comportements déjà 
obtenus sur les modèles à basse résolution.

Nos études n'ont pas permis de mettre en évidence des régimes dynamiques nouveaux propres aux échelles temporelles fines et 
à l'activité discrète.
Cependant, certains effets de mémoire à court terme, %ont pu être mis en évidence dans
%les réseaux aléatoires à spikes, 
sur le principe du ``réservoir'' de dynamiques vu précédemment,
ont montré que l'activité auto-entretenue 
permet la prise en compte de dépendances entre des événements séparés par 
plus de 100 ms \cite{henry07}.
La présence de séquences d'activation spatio-temporelles reproductibles (dites ``groupes polychrones''), 
telles que postulées par \cite{Izh06} en tant
qu'unités opérationnelles élémentaires, peut être mise en évidence dans nos réseaux aléatoires.
Une étude que j'ai publiée récemment, utilisant des unités neuronales un peu plus détaillées \cite{Dau14a} 
montre que la réponse de
population à des stimuli spatio-temporels suit une séquence reproductible (mais bruitée) qui 
peut être amplifiée par la plasticité.
La sensibilité acquise à des patrons spatio-temporels spécifiques, telles qu'existant également dans les modèles fréquentiels (voir \ref{sec:FPos}), 
peut donc etre observée à l'échelle de quelques millisecondes, mettant en jeu un faible nombre de spikes par neurone.
La clé semble donc être la mise en évience de mécanismes similaires à différentes échelles, les opérations
à échelle temporelle courte étant elles-même ``portées'' (ou embarquées) dans des opérations à échelle temporelle plus larges.


%Cette reproductibilité dans le temps et dans l'espace de la réponse du réseau au
%signal d'entrée offre un cadre d'explication intéressant pour 

{\color{Violet}
Fred Henry : Master en 2005.

bourse these : 
juin 2005 Ste Marguerite (initiation de neurocomp)

These Fred : pb : le lien avec le mouvement?

* 2005-2006 * 

oct. 2005 NOLTA - 

jan 2006 institut H Poincaré - 

juillet 2006 CNS à Edinbourg (modèle Gaussien du Master)

* 2006-2007 *

Dyva en sept 2006 présenté par Fred - idées orientées neural field + colliculus + LIF simple

oct. 2006 premiere conf. Neurocomp - 
idées RL + couche récurrente intermédiaire. 
Policy Gradient (Bartlett) = local changes = Hebb/anti-Hebb
Idée d'interversion bruit/signal dans les modèles à 2 couches (Gaussiennes centrées?).
Illustration avec simu Khepera.

juin 2007 - NIPS (refusé). 
modèle LIF/SRM à courant (avec free mb. potential h). 
- Connexions gaussiennes centrées . DELAI FIXE (10 ms)
STDP --> activité périodique non synchronisée

papier EPJ-ST : modèle RL Hebb/anti-Hebb avec terme (1-H) (comme SAB) sur liens excitateurs - separation exc/inh.

* 2007-2008 *  

Dyva en sept 2007 (signé Daucé) - poursuite approche RL-PG appliquée aux saccades.
(Fred ne participe pas à ce projet)

ESANN avril 2008 : idem NIPS sauf DELAI VARIABLE (Poisson moy. 10 ms). STDP produit oscillations lentes.

Tentative publi dans neurocomputing - echec. (calcul plus fin de la ``loading capacity'' - !! sur ordi Centrale only)


* ATER Lille 2008-2009 *

oct. 2008 - 2eme Neurocomp. Distinction input courant/input potentiel. differents regimes sont obtenus selon le type
d'input / les parametres internes.

juillet 2009 : CNS - séparation excitateurs/inhib. Plasticité sur exc. seulement. delais variables. effet 
stdp sur delais.

septembre 2009 : suite projet RL. 

ACI 'temps et cerveau' va de 2002 à 2007 (5 ans???)

MAPS commence en septembre 2007 (le dossier a été monté en janvier-février 2007)


{\bf 2008}
- modèles à 2 couches (strictly excitatory/inhibitory). 

{\bf 2009}

- “Free membr. potential” (synaptic input) / modeles ECM à “horizon fini” 

Mean field

Mon apport :
- Multi-pop
- Délais
- frontiere
- contrib. Reseaux equilibrés --> comportementdes réseaux équilibrés à la frontière
 
On-off states?
}

\subsection{Multistabilité dans les modèles ``large échelle''}

L'organisation à large échelle de l'activité du cerveau reposait jusqu'à récemment sur l'étude des différentiels d'activation
observé en imagerie fonctionnelle. L'apparition récente des techniques de tractographie par tenseurs de diffusion \cite{leBihan2001} permet d'analyser 
la matière blanche du cerveau pour suivre la direction des  faisceaux de fibres. 
Il est possible d'en déduire un patron de connectivité (le ``connectome'') reliant les principales régions du cortex. 
Le patron de connectivité issu de cette analyse forme un réseau, constitué par deux matrices, l'une fournissant la distance entre les
régions connectées, l'autre fournissant le ``poids'' de cette connexion en fonction de la densité de fibres.
Ce réseau est relativement stable à travers les sujets.
%Différents indicateurs globaux ont été proposés [CIITATIONS] dont la déviation par rapport 
%à la moyenne vise à repérer (ou améliorer l'identifications) de pathologies [CITATIONS].

Le connectome offre une vue d'ensemble de l'architecture du cerveau.
L'analyse du connectome (analyse ``structurelle'')  vient en complément
de l'analyse des patrons d'activité observés dans l'exercice d'une tâche (analyse fonctionnelle).
%(les mêmes grandes autoroutes sont présentes)
Dans le cadre de cette analyse structurelle, 
plusieurs indicateurs ont été proposées pour distinguer les noeuds les plus centraux (les plus ``importants'')
des noeuds périphériques. Il est possible de mettre en évidence d'un ``noyau central'' \cite{Hagmann2008}  
regroupant des noeuds médians servant de lien (ou de relais) entre la plupart des autres régions.
Cet ensemble de noeuds présente des points communs avec le patron d'activité ``par défaut'' observé en imagerie fonctionnelle 
(l'activité observée lorsque le sujet n'est pas occupé à accomplir une tâche) \cite{Raichle2001}. 

En complément de cette analyse structurelle, 
le projet ``The Virtual Brain'' (TVB) \cite{Leon2013}, 
porté par Viktor Jirsa, vise à combiner la connaissance anatomique et connectomique pour 
produire des simulations de l'activité électrique à large échelle du cerveau. 
Le modèle proposé repose d'une part sur la diffusion isotropique de
l'activité électrique sur la surface corticale (de type ``Neural Field''), 
et d'autre part la prise en compte de la connectivité longue distance. 

Dans le cadre d'un travail de co-direction de la thèse de Mathieu Golos à l'Institut de Neurosciences des Systèmes, 
j'ai contribué à une étude sur la multistablité dans les systèmes neuronaux artificiels
construits à partir du connectome \cite{Golos2014}. Nous sommes partis d'un 
modèle simplifié ignorant le terme de diffusion latérale. 
Chaque noeud du réseau est simplement identifié à une masse neuronale. 
Partant de l'analogie avec les réseaux de Hopfield \cite{Hop82}, le but
était d'identifier le nombre et l'organisation anatomique des
attracteurs se développant au sein d'un tel réseau.
Nous avons étudié différentes variantes du modèle ``à réponse graduelle'' de Hopfield \cite{Hopfield1984}, 
en changeant les caractéristiques du seuil d'activation afin de contrôle le niveau d'activation moyen.
Ces travaux ont permis de mettre en évidence un nombre très important d'attracteurs dans certaines gammes de paramètres.
Ainsi, en condition de ``basse température'', le nombre d'attracteurs distincts peut atteindre plusieurs milliers
(sur un modèle comportant 998 noeuds). %cette prolifération d'attracteurs est un indicateur du caractère 
L'analyse des ensembles d'attracteurs obtenus permet d'identifier une douzaine de ``modes'' différents, chaque
mode correspondant à l'activation d'une région anatomique particulière. Ces modes peuvent être comparés aux modules 
régionaux mis en évidence par une analyse structurelle \cite{Hagmann2008} ainsi qu'avec les composants indépendants 
identifiés sur les signaux fMRI de l'état de repos \cite{Damoiseaux2006}.

L'ajout d'un terme de bruit dans l'équation de mise à jour permet de simuler une activité multistable \emph{temporellement}, 
s'apparentant aux régimes dits de ``dynamique itinérante'' \cite{Tsuda1992,Kaneko2003},
et dont les catactéristiques sont plus proches des signaux observés à l'état de repos. 
Cette multistabilité temporelle conduit fréquemment le réseau vers des régimes d'activité plus simples 
(noeuds uniformément actifs
ou inactifs) par dérive lente de l'activité moyenne. 
Seul un modèle à ``feedback négatif global'' présente une multistabilité temporelle à long terme,
grâce au conrôle du niveau d'activité  qui empêche d'atteindre les régimes triviaux.

{\color{Violet}

{\bf 2011}

- approche Hopfield / connectome. Adatron pour “connectome inverse”

{\bf 2012}

- Connectome-based simulation : multistabilité spatiale et temporelle 

{\bf 2014}

- Connectome : identification de patchs à travers les patrons statiques (modele verre de spin). 

RSN

DTI

dualité covariance/causalité. 

connectivité structurelle / fonctionnelle
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     2      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Modèles de la perception à feedback positif} \label{sec:FPos}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

La plasticité est un processus physique qui impacte le comportement d'un substrat,
en modifiant son activité, sa réactivité à certaines entrées, ou le type de
réponse qu'il produit. 
La plasticité est la propriété qui donne au substrat une mémoire physique (par opposition
la mémoire dynamique), qui provoque un changement
d'état durable.
La plasticité permet d'inscrire sur
le support la trace de faits passés en vue d'une utilisation future.

Selon la perpective biologique et développementale, l'apprentissage
est le processus de changement comportemental, 
en relation avec ce mécanisme de plasticité. 
L'apprentissage est au sens large
l'ensemble des processus épigénétiques (historiques) inscrivant dans l'animal ou l'individu 
les éléments d'expérience qui contribuent à accroitre l'adaptation de ses réponses à son
milieu.  

La capacité à inscrire des événements en vue de les exploiter est une des
propriétés essentielle du système nerveux des être vivants, assez difficile
à reproduire en tant que telle sur un support artificiel.
Par exemple, dans une perspective computationnelle autonome, un programme doit pouvoir se passer d'utilisateur. 
La consigne doit provenir d'un programme interne (un "méta programme") qui 
agit sur le programme courant au fur et à mesure que de nouveaux événements se présentent.
Même si la notion de méta-programme ne pose pas de difficulté conceptuelle, elle est
en pratique difficile à mettre en oeuvre dans les architectures informatiques traditionnelles. 
La difficulté réside dans 
le choix des événements à considérer parmi l'ensemble des événements qui se présentent, et surtout 
dans la manière dont les événements pris en compte influencent le comportement logiciel futur.

Par analogie avec la biologie et le système nerveux, le principe de méta programme 
a principalement été implémenté dans 
un cadre logiciel qui est celui des réseaux de neurones artificiels.
On parle d'apprentissage automatique ("machine learning").
L'apprentissage est alors le processus qui modifie graduellement la
valeur des liaisons synaptiques entre les différents noeuds du réseau, dans 
le but d'augmenter la pertinence des réponses et des comportements produits.
Selon une perspective "supervisée", il s'agit d'inscrire dans la mémoire la trace de faits 
passés, dans le but de faciliter leur réapparition ou au contraire d'éviter qu'ils
ne se reproduisent.
Selon une perspective "non supervisée", il s'agit plutôt de réduire l'incertitude sur les faits nouveaux
grâce à la prise en compte des faits passés.

Le choix du modèle (du substrat artificiel) conditionne le type d'opérations, la nature des réponses
produites ainsi que la nature des changements autorisés.
L'ensemble de ces règles qui conditionnement l'évolution du substrat sous l'influence
des signaux à traiter constituent le méta-programme. 
Selon le cadre choisi, la convergence du modèle vers un comportement cible
adapté pourra être garanti sous certaines conditions (par exemple,
sous une condition de séparabilité linéaire dans le cadre du perceptron [CITATION]).

Les nombreux développements de l'apprentissage automatique permettent
BLA BLA BLA... prédicteur / classifieur. interpolation. 
Néanmoins, des pbs restent :

prise en compte des dépendances temporelles dans les données. persévérance

apprentissage "en ligne"

interpolation. auto-association. feedback positif

perception. connaissance et non-sens.

L'étude d'architectures neuronales à connectivité aléatoire ont permis 
de mettre en évidence des comportements de réseau conduisant 
à des formes d'organisation spontanée~: comportement critique, bifurcations,
transitions entre différents régimes dynamiques, activité persistante,
mémoire à court terme (rémanence) etc...
L'aléa des patrons de connexion et le caractère non-linéaire des opérateurs 
permet de produire une grande variété de configurations
d'activité, difficiles à prédire dans le détail.  

Le caractère pseudo-stochastique et organisé de la dynamique intrinsèque des réseaux
récurrents aléatoires peut servir de base à 

Existence de modes au sein du substrat

UP/DOWN + criticalité

% D'apres le mecanisme de Hopfield, la memoire est principalement un mecanisme d'interpolation

Mon apport :
Architectures perceptives (ou perceptuo-motrices) avec predictive coding en feedback positif (completion perceptive), 
contrairement au predictive coding qui repose sur un feedback negatif. Les deux approches reposent sur des premisses differentes. 
Le probleme de l’explosion catastrophique de l’activité (feedback positif) est resolu 
(1) par mecanisme de fatigue - la désynchronisation suit la synchronisation, 
(2) par la resistance au changement et 
(3) par le retour vers l’etat “OFF” par dissonance (mecanisme analogue à l’erreur perceptive).

Critique du feedback négatif : modele purement reactif. Pas de mecanisme pour la persistance des croyances (memoire à court terme)

analogie : le fond et la forme. Le paysage (par defaut) est non perçu. Soudain j’aperçois la  tete de mon voisin par dessus la haie (surprise par rapport au prior). Ce faisant, je suppose que le reste de son corps est caché par la haie (que la tete ne “flotte” pas en l’air). si je constate soudain que la tete flotte en l’air, je perçois tres fortement cette absence de corps (alors que le corps, comme etant une partie de la “cause” voisin, est anticipée sans etre perçue)

Idée : j'affecte des attributs à un sujet. Analogie de la bulle qui se deplace sur la carte. Je constate que mon voisin a un pull rouge. Je lui attribue (institue) l’attribut “rouge”. Mon voisin se deplace dans mon champ visuel. La qualité “rouge” se deplace avec lui par effet du binding (entrainement du binding) $\Rightarrow$ Nous passons notre temps à “peindre” le monde, à dessiner un tableau vivant. 

% un point important : la prise en compte des delais!!! conditionne l'anticipation sensorielle, la synchronisation agent-environnement, l'apprentissage de séquences.

% perception et non-sens

% L'idée de Freeman. L'enregistrement multi-électrodes. Potentialité et instanciation (choix d'une orbite). 


- Potentialité et instanciation. Réservoir. Emergence = instanciation. Irréversibilité (historique). Sculpture du vivant. Réduction d'incertitude. Plasticité, STDP, Hebb...

- Perception et non-sens. Pattern matching. UP/DOWN states. Ecart au modèle (Bayesian surprise). Predictive coding.
Activité de base. Reconnaissance par franchissement d'un seuil (``vigilance''). Distinction  entre connu et non-perçu (non-sens).
Modèles de la perception. Freeman.

OPERATION DE BASE :
La sensibilité \emph{acquise} à des patrons spatio-temporels spécifiques

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     2.1      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Route inverse}

{\bf Daucé, E., Quoy, M., Cessac, B., Doyon, B. and Samuelides, M. (1998) Self-organization and dynamics reduction in recurrent networks : stimulus presentation and learning, Neural Network 11:521-533}

{\bf Daucé E. and Doyon, B. (1998) Novelty Learning in a Discrete Time Chaotic Network, proc. of the 8th International Conference on Artificial Neural Networks (ICANN'98), L. Niklasson et al. eds, Vol. 2: 1051-1056, Springer, September 2-4, Skövde, Sweden}


- Une méthode d’apprentissage “non-supervisée” (il s’agit de capturer un mode dynamique)

- mecanisme de base de la route inverse. Notion de “reduction” de la dynamique par apprentissage (baisse de l’impredictibilité, analogie possible avec exploration/exploitation)

- encodage - patrons statiques - route vers le chaos - destabilisation - frontière du chaos


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     2.2      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Architectures multi-couches}

{\bf 1999}

- reseaux à 2 pop : couche primaire et couche secondaire (perceptive).  Mecanisme de “resonance perceptive” (et “resistance au changement”). Importance des delais. 

- patrons conditionnants (= contexte)

- règle de covariance - Règle d’ordre 2 (différence-based / covariance rule) 

{\bf 2000-2001}

- Perception par feedback positif. Apprentisage “supervisé par la couche primaire”. La couche primaire est à la fois l’entrée et la sortie.

(Implicitement : 
(1) Réseau aléatoire avec delais = réservoir de séquences instables dont certaines s’instancient (“emergence”)
(2) Predictive coding avant l’heure (de type interpolation)
(3) Controle moteur “supervisé”

{\bf Daucé, E., Quoy, M. and Doyon, B. (2002) Resonant spatio-temporal learning in large random recurrent networks, Biol.Cybern. 87(3):185-198}

- implémentation d’un mécanisme de résonance support de la perception et de la mémoire (en particulier generalisation du principe d’interpolation de Hopfield dans le domaine spatio-temporel). Importance des delais dans le traitement temporel.

- alternances synchronisation (perçu) / non-sens. Système de perception dual. Figure sur fond (Gestalt). 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     2.3      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Plasticité dans les réseaux équilibrés}

{\bf 2008}

- Balanced networks et STDP.

{\bf 2014}

- population response (population “spike”) avec STDP. Importance des termes de reequilibrage des poids et de la SFA.  Idée de multi-échelle et de detecteur d’information mutuelle à travers l’activité. Idée de STDP comme sequence enhancement.

UP/DOWN

Brunel

Frequences, rythmes, periodicités




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     2.4      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Plasticité séquentielle}

{\bf 2005}

- analogie TD - STDP.  Règle de la difference : (Si(t+1) - Si(t)) Sj(t)

- Hebb / anti-Hebb

{\bf 2006} 

- STDP / anti STDP pour le RL 

{\bf 2007}

- synaptic scaling

- regles de Hebb ordre 0 ou 1. Contrast enhancement vs. covariance (sequence) enhancement 

CAUSALITE (interp. de la STDP en termes de causalité). 

SYNCHRONISATION (Information mutuelle acausale/simultanée = co-évolution).



% STDP

% Le point de vue informationnel : MI??




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     3      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Bruit générateur/bruit destructeur dans les couplages sensori-moteurs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Intro : la logique du vivant : processus de fabrication qui construit les briques permettant de réparer/entretenir  
le processus de fabrication lui-même.
Le processus n'a pas d'autre finalité que l'entretien indéfini de lui-même (dans le cadre d'un système fermé ``poreux'' loin
de l'équilibre, avec des intrants (nutriments, énergie) et des déchets).
Si la cognition s'incarne dans le vivant, elle ne peut avoir de fonction autre que d'augmenter la robustesse du
procesus qui lui donne naissance. 

Questino : ``où'' est prise la décision? ``Lieu'' de la décision à l'interface entre intérieur et extérieur.

Mon apport :

Principe du miroir (environnement (milieu) ``agissant sur'' l'agent)

L'environnement (milieu) inclut le corps et les actuateurs.

L'action est intrinsèquement relationnelle/communicationnelle (transactionnnelle?).

% Modèlmes RL - Actor--critic
L'activité intrinsèque (non necessairement bruit). ``sculpte'' la reponse comportementale par des phénomènes de résonance.  
Bruit destructeur / bruit createur. Darwinisme. On peut voir le bruit d'etat comme un facteur perturbateur de couplage. 

Rappels sur les 2 approches synthétisees dans EPJST : supervisé et renforcement.

L'apprentissage par renforcement apporte une notion nouvelle : bruit générateur (créateur). ``création d'information'' : ``enact'' (promulguer) 
création de faits nouveaux (orientations nouvelles, deplacements nouveaux, emplois nouveaux). ``Angle mort'' des sciences cognitives. 
Contingence et capture. 
Il est important de distinguer l'approche ``pattern matching'' qui repose sur une capture passive des regularites statistiques et l'approche RL qui à la fois capture 
et genere les patterns.
Conceptuellement problematique du point de vue de la theorie de l'information (notion d'emetteur et de recepteur brouillées), sauf peut-etre du point de vue global (inobservé)
auquel cas il n'y a ni emetteur ni recepteur.

On peut assimiler un fait à un couple (perception, action).

- Fluctuation. Bruit - activité fluctuante. Activité intrinsèque. Activité de base. Création d'information. Capture. (Exemples de capture : le modèle acteur-critique, le réservoir computing).
Notion d'activité centrale fluctuante. Le chaos. Le bruit comme élément générateur, source de nouveauté.
L'activité intrinsèque n'est pas uniquement feed-forward (traitement du signal), lateral (inference) ou feedback (rappel). 
Il faut considérer la fluctuation imprévue et la création d'information. 
L'exploration apparait nécessaire dans les environements complexes : lorsque l'espace des tâches est complexe. Periode de jeu chez les mammifères. 
{\bf Fonction des fluctations = capture de nouveaux couplages dans un environnement complexe}

Et bien sûr approche énactive : on ne perçoit que ce sur quoi on peut agir. 
"Le monde (visuel) est (quelque chose qui est) constitué par l'action" (Varela)

La théorie du renforcement a tendance à définir l'activité comme reflétant la valeur de la situation (du couple (s,a)).
Dans ce cadre, l'état du système n'est pas une représentation du monde exterieur mais plutot une batterie de ``notes'' attribuées
aux différentes réponses motrices potentielles étant donnée la situation .

% L'état central fluctuant est popularisé par J-D Vincent

- Engagement et action. Commande. Architectures de contrôle. Espace des tâches. Couplages corps-environnement (Friston). Organisme transitoire (Société des organes). 

Les variables de contrôle (rewards) arrivent par d'autres canaux. 

et aussi ``rewards correspond to innate priors that constrain policies.''

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     3.1      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Généralités}

{\bf 2000-2001}

{\bf Daucé, E. (2002) Systèmes dynamiques pour les sciences cognitives, in Approche dynamique de la cognition artificielle, Guillot, A. and Daucé, E. eds :33-44, Lavoisier, Paris, France}

- couplage = utilisation = perte d’autonomie transitoire (voir aussi introduction Hermes).  

- controle supervise par modele inverse

{\bf Daucé, E., Quoy, M. and Doyon, B. (2002) Resonant spatio-temporal learning in large random recurrent networks, Biol.Cybern. 87(3):185-198}

{\bf Quoy M. and Daucé, E. (2000) Visual and motor learning using a chaotic recurrent neural network: application to the control of a mobile robot, proc. of the  Second International ICSC Symposium on Neural Computation (NC2000), Bohte, H. and Rojas, R. eds: 577-582, May 23-26, Berlin, Germany}

{\bf Daucé E. and Quoy, M. (2000) Random recurrent neural networks for autonomous systems design, additional, proc. of the sixth international conference on Simulation of Adaptive Behavior : From Animals to Animats (SAB 2000), Meyer, J.-A. et al. eds:31-40, Sept. 11-15, Paris, France}

{\bf Quoy, M., Banquet, J.-P. and Daucé, E. (2001) Learning and control with chaos : from biology to robotics, Behavioral and Brain Sciences 24(5):824-825}

- Comportement d’itinerance au niveau du couple agent/environnement (robot ETIS). “Accrochage” = perte d’autonomie / information mutuelle. Alternance entre synchronisation et désynchronisation (bruit destructeur).

{\bf 2007}

- Modele en miroir

- extension du Q-learning aux espaces d’entrée/sortie vectoriels. Idee etat interne = valeur.

slow external / fast internal

intensif / extensif

codage topographique / codage scalaire

Closed form


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     3.2      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Contrôle adaptatif en boucle fermée} 


NB : modèles feed-forward pour saccade - bras - BCI 

{\bf 2002}

- Tentatives contrôle en boucle fermée (Khepera). Premieres implementation du RL (reward-based learning) avec Hebb et anti-Hebb. 

{\bf 2003-2004}

- RL hebbien concurrent  : signal/bruit

- prémisses de la règle de policy gradient (1-P) xi(t) xj(t-1)

{\bf Daucé, E. (2004) Hebbian reinforcement learning in a modular dynamic network, proc. of the eighth international conference on Simulation of Adaptive Behavior : From Animals to Animats (SAB*04), Schaal, S. et al. eds:305-314, July 13-17, Los Angeles, CA, USA}

- lien Hebb et PG?

- alternance bruit/signal (selon la classe de liens)


{\bf 2005}

{\bf Daucé, E., Soula, H. and Beslon, G. (2005) Learning Methods for Dynamic Neural Networks, proc. of the 2005 International Symposium on Nonlinear Theory and its Applications (NOLTA'05):598-601, Oct. 18-21, Bruges, Belgium}

- RL / chaos $\Rightarrow$ exploration chaotique

{\bf 2009}

- Slow noise for RL in spiking neural networks

{\bf 2010}

- RL in continuous time and space (avec Alain D)


% David Marr : fonctions du cervelet, du neocortex et de l'hippocampe.

% Distinction entre l'espace metrique/physique et l'espace intentionnel (controlleur. Distinction reposant principalement sur les constantes de temps.

% le robot qui tourne. UP/DOWN? ``accochage/résonnance'' - point de vue global - analogie itinerance

%\fbox{
%\begin{minipage}
%\includepdf[pages=1-10]{pdf/epj-st-2007.pdf}
%\end{minipage}
%}
% Histoires


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     4      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Architectures de contrôle pour les neurosciences}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

principe général : 
- comportement based
- mapping des architectures de contrôle sur le SNC

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     4.1      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Modèles de l'orientation spatiale}

{\bf 2010}

- A. Mouraud : mecanisme integrateur. Dual drive. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     4.2      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Modèles de l'orientation temporelle}

{\bf 2010}

- Gaurav : attention temporelle. Modele EM. 


{\bf 2011}

- scalar property

$\Rightarrow$ prior $\simeq$ ``\% up to now'' (subjective time)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     4.3      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Apprendre et oublier dans les environnements non-stationnaires}

{\bf 2011}

- Policy gradient dans les BCI. Reward adaptatif. Baseline optimale. 

{\bf 2013}

- Oddball problem / lien avec convolution networks et/ou ranking.

- Approche adaptative des BCI : label free logistic gradient descent avec accumulation d’évidence + subject-independent classifier.

- Hongliang : Passive Agressive + bandit feedback




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Projet scientifique}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\bf 1999}

- Philo 1 : non-extensivité des sensations - analogie “zone aveugle”

{\bf 2000-2001}

- travail de biblio sur l’hippocampe. 

{\bf 2003-2004}

- Philo 2: pensée à l’échelle temporelle de nos actes

{\bf 2009}

- travail sur les structures sous-corticales : striatum/tectum/cervelet 

{\bf 2010}

- Premier modele (nu,theta)

En particulier : la notion d'expressivité du substrat est prometteuse. 

- Variables de contrôle. Equilibre dynamique. Homeostasie. Emploi et Couplage sans emploi. Répertoire (dictionnaire?) d'emplois. 

- Neurone hédoniste.
IDEE : DU POINT DE VUE DU NEURONE HEDONISTE, LES SPIKES EMIS DOIVENT AVOIR POUR CONSEQUENCE DE MIEUX SOUMETTRE LE NEURONE A DE NOUVELLES STIMULATIONS - PRIOR SUR L’EXPOSITION AUX STIMULATIONS FUTURES.




Perspectives :
\begin{itemize}
\item Substrat apprenant universel
\item Field computation. Patron (fenêtre) d’interaction anisotropique. La reponse n’est pas un vecteur ou un scalaire mais une distribution.
\item Regles de plasticité, information mutuelle et binding. Synchronie des systemes en interaction. Le binding au niveau des schémas d’interaction en miroir. Co-evolution. Mutual information (avec mutual emission et reception). Accrochage de phase. Emergence et non-sens. Independance : est “bindé” ce qui évolue ensemble (non indépendamment). Est “non bindé” ce qui évolue indépendamment. Lié aux DDL? 
$\Rightarrow$ Le substrat est le support de plusieurs processus indépendants. Par analogie au neural field, on peut avoir plusieurs “bulles” sur la carte.
\item idée de perméabilité / imperméabilité des echelles BOTTOM $\rightarrow$ UP. Les etats et les processus des echelles inferieures ne sont pas impactées par les phenomenes d’ordre superieur autrement que par les signaux et les tâches traitées à leur échelle. Exemple : une couche motrice est principalement en train de stabiliser des couplages, pas d’instituer (proclamer/décréter) un nouvel “emploi”. (pas de “downward causation”)
\end{itemize}

\chapter{Conclusion}

Les fondateurs des sciences cognitives ont placé très tôt la question de l'apprentissage  au coeur de leur problématique 
(qu'est-ce qu'une machine intelligente - cf. Turing)

Deux approches/réponses se dessinent dès l'origine :  
\begin{itemize}
 \item traitement symbolique
 \item traitement analogique
\end{itemize}
L'enjeu principal est celui d'un côté du traitement analogique et de l'autre le traitement symbolique. Du point de vue des sciences cognitives naissantes, c'est le traitement
symbolique qui gagne dans un premier temps.

Dans ces deux formalismes, la question de l'apprentissage a eu tendance à progressivement se marginaliser au profit (1) du traitement logique des symboles et de modèles
 descriptifs du langage (grammaires génératives) et (2) l'ingéniérie et la conception de systèmes d'asservissement de plus en plus complexes et/ou psychologie et constructivisme (Palo Alto)

A l'inverse, la question de l'apprentissage est restée présente dans le domaine des sciences de l'information et l'informatique naissante. 
La question de l'apprentissage  devient la question de construire des programmes (des automates) capables de se modifier, de s'amender pour mieux répondre aux sollicitations
de l'environnement. Cette question étant posée (comment modifier le programme sans intervention humaine), le formalisme des réseaux de neurones et du calcul distribué 
s'est révélé le plus apte à traiter la question --> le perceptron. 

\bibliographystyle{unsrt}%{apacite}
\bibliography{biblio}


\end{document}
